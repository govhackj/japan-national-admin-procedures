#!/usr/bin/env python3
"""
è¡Œæ”¿æ‰‹ç¶šç­‰ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³ ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ãƒ»åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

æ—¥æœ¬ã®æ³•ä»¤ã«åŸºã¥ãè¡Œæ”¿æ‰‹ç¶šç­‰ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³ã‚’å¯è¦–åŒ–ãƒ»åˆ†æã™ã‚‹
Streamlitãƒ™ãƒ¼ã‚¹ã®å¯¾è©±çš„ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ„ãƒ¼ãƒ«
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from pathlib import Path
from typing import Dict, List, Any
import re
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import networkx as nx
from pyvis.network import Network
import streamlit.components.v1 as components
import warnings

warnings.filterwarnings('ignore')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="è¡Œæ”¿æ‰‹ç¶šç­‰ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
DATA_DIR = Path(__file__).parent / "docs"
CSV_FILE = DATA_DIR / "20250729_procedures-survey-results_outline_02.csv"
PARQUET_FILE = DATA_DIR / "procedures_data.parquet"

# CSVã®ã‚«ãƒ©ãƒ å®šç¾©
COLUMNS = [
    "æ‰‹ç¶šID",
    "æ‰€ç®¡åºœçœåº", 
    "æ‰‹ç¶šå",
    "æ³•ä»¤å",
    "æ³•ä»¤ç•ªå·",
    "æ ¹æ‹ æ¡é …å·",
    "æ‰‹ç¶šé¡å‹",
    "æ‰‹ç¶šä¸»ä½“",
    "æ‰‹ç¶šã®å—ã‘æ‰‹",
    "çµŒç”±æ©Ÿé–¢",
    "ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰ã®åç§°",
    "äº‹å‹™åŒºåˆ†",
    "åºœçœå…±é€šæ‰‹ç¶š",
    "å®Ÿæ–½åºœçœåº",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½äºˆå®šåŠã³æ¤œè¨æ™‚ã®æ‡¸å¿µç‚¹",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸ",
    "ç”³è«‹ç­‰ã«ãŠã‘ã‚‹æœ¬äººç¢ºèªæ‰‹æ³•",
    "æ‰‹æ•°æ–™ç­‰ã®ç´ä»˜æœ‰ç„¡",
    "æ‰‹æ•°æ–™ç­‰ã®ç´ä»˜æ–¹æ³•",
    "æ‰‹æ•°æ–™ç­‰ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç´ä»˜æ™‚ã®å„ªé‡æªç½®",
    "å‡¦ç†æœŸé–“(ã‚ªãƒ³ãƒ©ã‚¤ãƒ³)",
    "å‡¦ç†æœŸé–“(éã‚ªãƒ³ãƒ©ã‚¤ãƒ³)",
    "æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)",
    "æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)",
    "ç·æ‰‹ç¶šä»¶æ•°",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°",
    "éã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°",
    "ç”³è«‹æ›¸ç­‰ã«è¨˜è¼‰ã•ã›ã‚‹æƒ…å ±",
    "ç”³è«‹æ™‚ã«æ·»ä»˜ã•ã›ã‚‹æ›¸é¡",
    "æ·»ä»˜æ›¸é¡ç­‰æå‡ºã®æ’¤å»ƒ/çœç•¥çŠ¶æ³",
    "æ·»ä»˜æ›¸é¡ç­‰ã®æå‡ºæ–¹æ³•",
    "æ·»ä»˜æ›¸é¡ç­‰ã¸ã®é›»å­ç½²å",
    "æ·»ä»˜å½¢å¼ç­‰ãŒå®šã‚ã‚‰ã‚ŒãŸè¦å®š",
    "æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)",
    "æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)",
    "ç”³è«‹ã«é–¢é€£ã™ã‚‹å£«æ¥­",
    "ç”³è«‹ã‚’æå‡ºã™ã‚‹æ©Ÿé–¢"
]

# --- é …ç›®å®šç¾©ï¼ˆè¦ç´„ï¼‰ & è¡¨ç¤ºé † ---
FIELD_DEFS: Dict[str, str] = {
    "æ‰€ç®¡åºœçœåº": "æ‰‹ç¶šã®æ ¹æ‹ æ³•ä»¤ï¼ˆæ¡æ–‡ï¼‰ã‚’æ‰€ç®¡ã™ã‚‹åºœçœåºã€‚",
    "æ‰‹ç¶šå": "æ‰‹ç¶šã®åç§°ã€‚",
    "æ³•ä»¤å": "æ‰‹ç¶šã®æ ¹æ‹ ã¨ãªã‚‹æ³•ä»¤ã®æ­£å¼åç§°ã€‚",
    "æ³•ä»¤ç•ªå·": "æ ¹æ‹ æ³•ä»¤ã®æ³•ä»¤ç•ªå·ã€‚",
    "æ ¹æ‹ æ¡é …å·": "æ ¹æ‹ æ¡ãƒ»é …ãƒ»å·ã®ç•ªå·ã€‚",
    "æ‰‹ç¶šé¡å‹": "1ç”³è«‹ç­‰ / 2-1ç”³è«‹ç­‰ã«åŸºã¥ãå‡¦åˆ†é€šçŸ¥ç­‰ / 2-2ç”³è«‹ç­‰ã«åŸºã¥ã‹ãªã„å‡¦åˆ†é€šçŸ¥ç­‰ / 2-3äº¤ä»˜ç­‰(æ°‘é–“æ‰‹ç¶š) / 3ç¸¦è¦§ç­‰ / 4ä½œæˆãƒ»ä¿å­˜ç­‰ã€‚",
    "æ‰‹ç¶šä¸»ä½“": "æ‰‹ç¶šã‚’è¡Œã†ä¸»ä½“ï¼ˆå›½ã€ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰ã€åœ°æ–¹ç­‰ã€å›½æ°‘ç­‰ã€æ°‘é–“äº‹æ¥­è€…ç­‰ ç­‰ã®çµ„åˆã›ã‚’å«ã‚€ï¼‰ã€‚",
    "æ‰‹ç¶šã®å—ã‘æ‰‹": "ç”³è«‹ç­‰ã«ãŠã„ã¦æœ€çµ‚çš„ã«æ‰‹ç¶šã‚’å—ã‘ã‚‹è€…ï¼ˆå›½ã€ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰ã€åœ°æ–¹ç­‰ã€å›½æ°‘ç­‰ã€æ°‘é–“äº‹æ¥­è€…ç­‰ ç­‰ï¼‰ã€‚",
    "çµŒç”±æ©Ÿé–¢": "æ³•ä»¤ã«åŸºã¥ãç”³è«‹ç­‰ã®æå‡ºæ™‚ã«çµŒç”±ãŒå¿…è¦ãªæ©Ÿé–¢ã®ç¨®åˆ¥ã€‚",
    "äº‹å‹™åŒºåˆ†": "åœ°æ–¹å…¬å…±å›£ä½“ãŒè¡Œã†äº‹å‹™ã®åŒºåˆ†ï¼ˆè‡ªæ²»äº‹å‹™ / ç¬¬1å·æ³•å®šå—è¨—äº‹å‹™ / ç¬¬2å·æ³•å®šå—è¨—äº‹å‹™ / åœ°æ–¹ã®äº‹å‹™ã§ãªã„ï¼‰ã€‚",
    "åºœçœå…±é€šæ‰‹ç¶š": "å…¨åºœçœå…±é€š(â—‹) / ä¸€éƒ¨åºœçœå…±é€š(â—) / éå…±é€š(Ã—)ã€‚",
    "å®Ÿæ–½åºœçœåº": "å½“è©²æ‰‹ç¶šã‚’å®Ÿæ–½ã™ã‚‹åºœçœåºï¼ˆåºœçœå…±é€šæ‰‹ç¶šã¯å…¨å›ç­”ã‚’åˆ—æŒ™ï¼‰ã€‚",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³": "1å®Ÿæ–½æ¸ˆ / 2æœªå®Ÿæ–½ / 3é©ç”¨é™¤å¤– / 4ãã®ä»– / 5ä¸€éƒ¨å®Ÿæ–½æ¸ˆã€‚",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½äºˆå®šåŠã³æ¤œè¨æ™‚ã®æ‡¸å¿µç‚¹": "äºˆå®šã¾ãŸã¯æ¤œè¨æ™‚ã®æ‡¸å¿µï¼ˆåˆ¶åº¦æ”¹æ­£ã€ã‚·ã‚¹ãƒ†ãƒ æœªæ•´å‚™ã€åŸæœ¬ç´™ç­‰ï¼‰ã€‚",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸ": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½äºˆå®šå¹´åº¦ï¼ˆ2024ã€œ2030ä»¥é™ï¼‰ã€‚",
    "ç”³è«‹ç­‰ã«ãŠã‘ã‚‹æœ¬äººç¢ºèªæ‰‹æ³•": "æŠ¼å°ï¼‹å°é‘‘è¨¼æ˜ / æŠ¼å° / ç½²å / æœ¬äººç¢ºèªæ›¸é¡æç¤ºãƒ»æå‡º / ãã®ä»– / ä¸è¦ã€‚",
    "æ‰‹æ•°æ–™ç­‰ã®ç´ä»˜æœ‰ç„¡": "æ‰‹æ•°æ–™ç­‰ã®æœ‰ç„¡ã€‚",
    "æ‰‹æ•°æ–™ç­‰ã®ç´ä»˜æ–¹æ³•": "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼ˆçª“å£/éŠ€è¡Œ/ATM/ã‚³ãƒ³ãƒ“ãƒ‹ç­‰ï¼‰ãƒ»ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼ˆãƒšã‚¤ã‚¸ãƒ¼/ã‚¯ãƒ¬ã‚«/QRç­‰ï¼‰ã€‚",
    "æ‰‹æ•°æ–™ç­‰ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç´ä»˜æ™‚ã®å„ªé‡æªç½®": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç´ä»˜ã«ã‚ˆã‚‹æ¸›å…ã®æœ‰ç„¡ã€‚",
    "å‡¦ç†æœŸé–“(ã‚ªãƒ³ãƒ©ã‚¤ãƒ³)": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šã®æ¨™æº–å‡¦ç†æœŸé–“ã€‚",
    "å‡¦ç†æœŸé–“(éã‚ªãƒ³ãƒ©ã‚¤ãƒ³)": "éã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šã®æ¨™æº–å‡¦ç†æœŸé–“ã€‚",
    "æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)": "ç”³è«‹ç­‰ã«ä¿‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ åï¼ˆå—ä»˜/ç”³è«‹ï¼‰ã€‚",
    "æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)": "ç”³è«‹ç­‰ã‚’å—ã‘ãŸå¾Œã®äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åã€‚",
    "ç·æ‰‹ç¶šä»¶æ•°": "ä»¤å’Œ5å¹´åº¦ç­‰ã®å¹´é–“ç·ä»¶æ•°ï¼ˆæœ‰åŠ¹æ•°å­—2æ¡ç›®å®‰ã€è©¦ç®—å«ã‚€ï¼‰ã€‚",
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§å®Ÿæ–½ã—ãŸä»¶æ•°ï¼ˆè©²å½“æ‰‹ç¶šã®ã¿ï¼‰ã€‚",
    "éã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ä»¥å¤–ã§å®Ÿæ–½ã—ãŸä»¶æ•°ã€‚",
    "ç”³è«‹æ›¸ç­‰ã«è¨˜è¼‰ã•ã›ã‚‹æƒ…å ±": "ç”³è«‹æ›¸è¨˜å…¥ã®å¿…é ˆé …ç›®ï¼ˆãƒã‚¤ãƒŠãƒ³ãƒãƒ¼ã€æ³•äººç•ªå·ç­‰ï¼‰ã€‚",
    "ç”³è«‹æ™‚ã«æ·»ä»˜ã•ã›ã‚‹æ›¸é¡": "ç”³è«‹æ™‚ã«æå‡ºãŒå¿…é ˆã®å…¸å‹æ›¸é¡ï¼ˆä½æ°‘ç¥¨ã€æˆ¸ç±ã€ç™»è¨˜äº‹é …ç­‰ï¼‰ã€‚",
    "æ·»ä»˜æ›¸é¡ç­‰æå‡ºã®æ’¤å»ƒ/çœç•¥çŠ¶æ³": "æ·»ä»˜æ›¸é¡æ’¤å»ƒãƒ»çœç•¥ã®çŠ¶æ³ï¼ˆæ¸ˆ/äºˆå®š/ä¸å¯/ãã®ä»–ï¼‰ã€‚",
    "æ·»ä»˜æ›¸é¡ç­‰ã®æå‡ºæ–¹æ³•": "é›»å­/åŸç´™/ä¸€éƒ¨é›»å­ç­‰ã®æå‡ºæ–¹å¼ã€‚",
    "æ·»ä»˜æ›¸é¡ç­‰ã¸ã®é›»å­ç½²å": "æ·»ä»˜æ›¸é¡ã®é›»å­ç½²åã®è¦å¦ï¼ˆä¸è¦/ä¸€éƒ¨/å…¨ã¦ï¼‰ã€‚",
    "æ·»ä»˜å½¢å¼ç­‰ãŒå®šã‚ã‚‰ã‚ŒãŸè¦å®š": "æ³•ä»¤/å‘Šç¤º/ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜ç­‰ã®è¦å®šæœ‰ç„¡ã€‚",
    "æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)": "å€‹äººã®ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆå¦Šå¨ ã€å‡ºç”Ÿã€å¼•è¶Šã—ã€å°±è·ãƒ»è»¢è·ã€ç¨é‡‘ã€å¹´é‡‘ã€æ­»äº¡ãƒ»ç›¸ç¶š ç­‰ï¼‰ã€‚",
    "æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)": "æ³•äººã®ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆè¨­ç«‹ã€å½¹å“¡å¤‰æ›´ã€æ¡ç”¨ãƒ»é€€è·ã€å…¥æœ­ãƒ»å¥‘ç´„ã€ç§»è»¢ã€åˆä½µãƒ»å»ƒæ¥­ ç­‰ï¼‰ã€‚",
    "ç”³è«‹ã«é–¢é€£ã™ã‚‹å£«æ¥­": "ä»£ç†ç”³è«‹ãŒå¯èƒ½ãªå£«æ¥­ï¼ˆå¼è­·å£«ã€å¸æ³•æ›¸å£«ã€è¡Œæ”¿æ›¸å£«ã€ç¨ç†å£«ã€ç¤¾åŠ´å£«ã€å…¬èªä¼šè¨ˆå£«ã€å¼ç†å£« ç­‰ï¼‰ã€‚",
    "ç”³è«‹ã‚’æå‡ºã™ã‚‹æ©Ÿé–¢": "æå‡ºå…ˆæ©Ÿé–¢ï¼ˆæœ¬åºœçœåº/å‡ºå…ˆæ©Ÿé–¢/åœ°æ–¹å…¬å…±å›£ä½“ ç­‰ï¼‰ã€‚",
}

OPTION_ORDERS: Dict[str, List[str]] = {
    # è¦‹ã‚„ã™ã•ã®ãŸã‚ã®è¡¨ç¤ºé †ï¼ˆå­˜åœ¨ã—ãªã„å€¤ã¯ãã®ã¾ã¾æœ«å°¾ã«ï¼‰
    "æ‰‹ç¶šé¡å‹": [
        "ç”³è«‹ç­‰", "ç”³è«‹ç­‰ã«åŸºã¥ãå‡¦åˆ†é€šçŸ¥ç­‰", "ç”³è«‹ç­‰ã«åŸºã¥ã‹ãªã„å‡¦åˆ†é€šçŸ¥ç­‰",
        "äº¤ä»˜ç­‰ï¼ˆæ°‘é–“æ‰‹ç¶šï¼‰", "ç¸¦è¦§ç­‰", "ä½œæˆãƒ»ä¿å­˜ç­‰"
    ],
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³": ["å®Ÿæ–½æ¸ˆ", "ä¸€éƒ¨å®Ÿæ–½æ¸ˆ", "æœªå®Ÿæ–½", "é©ç”¨é™¤å¤–", "ãã®ä»–"],
    "æ‰‹ç¶šä¸»ä½“": ["å›½", "ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰", "åœ°æ–¹ç­‰", "å›½åˆã¯ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰", "ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰åˆã¯åœ°æ–¹ç­‰", "å›½åˆã¯åœ°æ–¹ç­‰", "å›½ã€ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰åˆã¯åœ°æ–¹ç­‰", "å›½æ°‘ç­‰", "æ°‘é–“äº‹æ¥­è€…ç­‰", "å›½æ°‘ç­‰ã€æ°‘é–“äº‹æ¥­è€…ç­‰"],
    "æ‰‹ç¶šã®å—ã‘æ‰‹": ["å›½", "ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰", "åœ°æ–¹ç­‰", "å›½åˆã¯ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰", "ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰åˆã¯åœ°æ–¹ç­‰", "å›½åˆã¯åœ°æ–¹ç­‰", "å›½ã€ç‹¬ç«‹è¡Œæ”¿æ³•äººç­‰åˆã¯åœ°æ–¹ç­‰", "å›½æ°‘ç­‰", "æ°‘é–“äº‹æ¥­è€…ç­‰", "å›½æ°‘ç­‰ã€æ°‘é–“äº‹æ¥­è€…ç­‰"],
    "äº‹å‹™åŒºåˆ†": ["è‡ªæ²»äº‹å‹™", "ç¬¬1å·æ³•å®šå—è¨—äº‹å‹™", "ç¬¬2å·æ³•å®šå—è¨—äº‹å‹™", "åœ°æ–¹ã®äº‹å‹™ã§ãªã„"],
    "åºœçœå…±é€šæ‰‹ç¶š": ["â—‹ï¼ˆå…¨åºœçœï¼‰", "â—ï¼ˆä¸€éƒ¨ã®åºœçœï¼‰", "Ã—ï¼ˆåºœçœå…±é€šæ‰‹ç¶šã§ãªã„)"]
}

# ---- æ­£è¦åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----
def _normalize_label(key: str, val: Any) -> str:
    s = str(val).strip()
    if s.lower() == 'nan' or s == '':
        return s
    # çµ±ä¸€ï¼šåŠè§’æ‹¬å¼§â†’å…¨è§’æ‹¬å¼§
    s = s.replace('(', 'ï¼ˆ').replace(')', 'ï¼‰')
    # å…ˆé ­ã®åˆ†é¡ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: 1 / 2-1 / 2-3 ç­‰ï¼‰ã‚’é™¤å»
    if key in ("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³", "æ‰‹ç¶šé¡å‹"):
        s = re.sub(r"^\s*\d+(?:-\d+)?\s*", "", s)
    # ã‚ˆãã‚ã‚‹è¡¨è¨˜ã‚†ã‚Œã®å¸å
    if key == "æ‰‹ç¶šé¡å‹":
        # ã€Œäº¤ä»˜ç­‰ï¼ˆæ°‘é–“æ‰‹ç¶šï¼‰ã€ã®è¡¨è¨˜ã‚†ã‚Œ
        s = s.replace("äº¤ä»˜ç­‰(æ°‘é–“æ‰‹ç¶š)", "äº¤ä»˜ç­‰ï¼ˆæ°‘é–“æ‰‹ç¶šï¼‰")
    return s

def normalized_counts(df: pd.DataFrame, column: str, key: str) -> pd.Series:
    if column not in df.columns or len(df) == 0:
        return pd.Series(dtype=int)
    series = df[column].dropna().map(lambda v: _normalize_label(key, v))
    vc = series.value_counts()
    order = OPTION_ORDERS.get(key)
    if order:
        ordered = vc.reindex([v for v in order if v in vc.index]).dropna()
        # ã‚‚ã—é †åºé©ç”¨ã§ç©ºã«ãªã£ãŸã‚‰ã€ç´ ã®ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if len(ordered) > 0:
            return ordered
    return vc

def order_series_by_option(series: pd.Series, key: str) -> pd.Series:
    order = OPTION_ORDERS.get(key)
    if not order:
        return series
    # dict for order index
    idx = {v: i for i, v in enumerate(order)}
    return series.sort_index(key=lambda s: s.map(lambda x: idx.get(x, len(idx))))

@st.cache_data(ttl=3600, show_spinner="ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
def load_data() -> pd.DataFrame:
    """Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é«˜é€Ÿèª­ã¿è¾¼ã¿ï¼ˆCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯å¤‰æ›ï¼‰"""
    
    # Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯CSVã‹ã‚‰å¤‰æ›
    if not PARQUET_FILE.exists() and CSV_FILE.exists():
        st.info("åˆå›èµ·å‹•ï¼šCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’Parquetå½¢å¼ã«å¤‰æ›ã—ã¦ã„ã¾ã™...")
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(
            CSV_FILE,
            encoding='utf-8-sig',
            skiprows=2,
            names=COLUMNS,
            dtype=str,
            na_values=['', 'NaN', 'nan'],
            low_memory=False
        )
        
        # ã‚«ãƒ†ã‚´ãƒªå‹ã«å¤‰æ›
        categorical_cols = ['æ‰€ç®¡åºœçœåº', 'æ‰‹ç¶šé¡å‹', 'æ‰‹ç¶šä¸»ä½“', 'æ‰‹ç¶šã®å—ã‘æ‰‹', 
                          'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', 'äº‹å‹™åŒºåˆ†', 'åºœçœå…±é€šæ‰‹ç¶š']
        for col in categorical_cols:
            if col in df.columns:
                df[col] = df[col].astype('category')
        
        # æ•°å€¤å‹ã«å¤‰æ›
        numeric_columns = ["ç·æ‰‹ç¶šä»¶æ•°", "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°", "éã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°"]
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int32')
        
        # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ã‚’è¨ˆç®—
        if 'ç·æ‰‹ç¶šä»¶æ•°' in df.columns and 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°' in df.columns:
            df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡'] = np.where(
                df['ç·æ‰‹ç¶šä»¶æ•°'] > 0,
                (df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'] / df['ç·æ‰‹ç¶šä»¶æ•°'] * 100).round(2),
                0
            ).astype('float32')
        
        # Parquetãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        df.to_parquet(PARQUET_FILE, engine='pyarrow', compression='snappy')
        st.success("å¤‰æ›å®Œäº†ï¼æ¬¡å›ã‹ã‚‰ã¯é«˜é€Ÿã«èª­ã¿è¾¼ã‚ã¾ã™ã€‚")
    
    # Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆè¶…é«˜é€Ÿï¼‰
    df = pd.read_parquet(PARQUET_FILE, engine='pyarrow')
    
    # ã‚«ãƒ†ã‚´ãƒªå‹ãŒç¶­æŒã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    categorical_cols = ['æ‰€ç®¡åºœçœåº', 'æ‰‹ç¶šé¡å‹', 'æ‰‹ç¶šä¸»ä½“', 'æ‰‹ç¶šã®å—ã‘æ‰‹', 
                      'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', 'äº‹å‹™åŒºåˆ†', 'åºœçœå…±é€šæ‰‹ç¶š']
    for col in categorical_cols:
        if col in df.columns and df[col].dtype != 'category':
            df[col] = df[col].astype('category')
    
    # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ãŒãªã„å ´åˆã¯è¨ˆç®—
    if 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡' not in df.columns:
        if 'ç·æ‰‹ç¶šä»¶æ•°' in df.columns and 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°' in df.columns:
            df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡'] = np.where(
                df['ç·æ‰‹ç¶šä»¶æ•°'] > 0,
                (df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'] / df['ç·æ‰‹ç¶šä»¶æ•°'] * 100).round(2),
                0
            ).astype('float32')
    
    return df

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.df = None

@st.cache_data
def get_unique_values(df, column):
    """ã‚«ãƒ©ãƒ ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
    if df[column].dtype.name == 'category':
        # ã‚«ãƒ†ã‚´ãƒªå‹ã®å ´åˆã¯é«˜é€Ÿå‡¦ç†
        return sorted([str(v) for v in df[column].cat.categories if pd.notna(v)])
    else:
        unique_vals = df[column].dropna().unique()
        # å…¨ã¦æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ã‹ã‚‰ã‚½ãƒ¼ãƒˆ
        return sorted([str(v) for v in unique_vals])

@st.cache_data
def filter_dataframe(df, ministries, statuses, types, recipients, actors=None, receivers=None, office_types=None, is_common=None, count_ranges=None):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰"""
    mask = pd.Series([True] * len(df), index=df.index)
    if ministries:
        mask &= df['æ‰€ç®¡åºœçœåº'].isin(ministries)
    if statuses:
        mask &= df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³'].isin(statuses)
    if types:
        mask &= df['æ‰‹ç¶šé¡å‹'].isin(types)
    if recipients:
        mask &= df['æ‰‹ç¶šã®å—ã‘æ‰‹'].isin(recipients)
    if actors:
        mask &= df['æ‰‹ç¶šä¸»ä½“'].isin(actors)
    if receivers:
        mask &= df['æ‰‹ç¶šã®å—ã‘æ‰‹'].isin(receivers)
    if office_types:
        mask &= df['äº‹å‹™åŒºåˆ†'].isin(office_types)
    if is_common:
        mask &= df['åºœçœå…±é€šæ‰‹ç¶š'].isin(is_common)
    
    # æ‰‹ç¶šä»¶æ•°ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if count_ranges:
        count_mask = pd.Series([False] * len(df), index=df.index)
        for range_str in count_ranges:
            if range_str == "100ä¸‡ä»¶ä»¥ä¸Š":
                count_mask |= df['ç·æ‰‹ç¶šä»¶æ•°'] >= 1000000
            elif range_str == "10ä¸‡ä»¶ä»¥ä¸Š100ä¸‡ä»¶æœªæº€":
                count_mask |= (df['ç·æ‰‹ç¶šä»¶æ•°'] >= 100000) & (df['ç·æ‰‹ç¶šä»¶æ•°'] < 1000000)
            elif range_str == "1ä¸‡ä»¶ä»¥ä¸Š10ä¸‡ä»¶æœªæº€":
                count_mask |= (df['ç·æ‰‹ç¶šä»¶æ•°'] >= 10000) & (df['ç·æ‰‹ç¶šä»¶æ•°'] < 100000)
            elif range_str == "1000ä»¶ä»¥ä¸Š1ä¸‡ä»¶æœªæº€":
                count_mask |= (df['ç·æ‰‹ç¶šä»¶æ•°'] >= 1000) & (df['ç·æ‰‹ç¶šä»¶æ•°'] < 10000)
            elif range_str == "100ä»¶ä»¥ä¸Š1000ä»¶æœªæº€":
                count_mask |= (df['ç·æ‰‹ç¶šä»¶æ•°'] >= 100) & (df['ç·æ‰‹ç¶šä»¶æ•°'] < 1000)
            elif range_str == "10ä»¶ä»¥ä¸Š100ä»¶æœªæº€":
                count_mask |= (df['ç·æ‰‹ç¶šä»¶æ•°'] >= 10) & (df['ç·æ‰‹ç¶šä»¶æ•°'] < 100)
            elif range_str == "1ä»¶ä»¥ä¸Š10ä»¶æœªæº€":
                count_mask |= (df['ç·æ‰‹ç¶šä»¶æ•°'] >= 1) & (df['ç·æ‰‹ç¶šä»¶æ•°'] < 10)
            elif range_str == "0ä»¶ã‚‚ã—ãã¯ä¸æ˜":
                count_mask |= (df['ç·æ‰‹ç¶šä»¶æ•°'] == 0) | df['ç·æ‰‹ç¶šä»¶æ•°'].isna()
        mask &= count_mask
    
    return df[mask]



# CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ˜ãƒ«ãƒ‘ãƒ¼
@st.cache_data
def df_to_csv_bytes(df: pd.DataFrame, columns: List[str] | None = None) -> bytes:
    if columns:
        df = df[columns]
    return df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')

# ---- Network utils ----
def _has_cols(df: pd.DataFrame, cols: List[str]) -> bool:
    missing = [c for c in cols if c not in df.columns]
    if missing:
        st.warning("å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: " + ", ".join(missing))
        return False
    return True

def _safe_notna(series: pd.Series) -> pd.Series:
    # category/objectåˆ—ã§ 'nan' æ–‡å­—åˆ—ãŒæ··ã˜ã‚‹ã‚±ãƒ¼ã‚¹ã‚’å¸å
    s = series.astype(str)
    return (s.str.lower() != 'nan') & (s.str.strip() != '')

def _layout_for_graph(G: nx.Graph):
    n = G.number_of_nodes()
    if n == 0:
        return {}
    if n <= 30:
        return nx.kamada_kawai_layout(G)
    # spring_layout ã¯é‡ã„ã®ã§åå¾©ã‚’æŠ‘ãˆã‚‹ & å›ºå®šseed
    return nx.spring_layout(G, k=1, iterations=30, seed=42)


# ---- PyVis renderer for interactive network visualization ----

def _render_pyvis(G: nx.Graph, height: int = 700):
    """Render a draggable/zoomable network with PyVis inside Streamlit."""
    net = Network(height=f"{height}px", width="100%", bgcolor="#ffffff", font_color="#333", cdn_resources='in_line')
    # Enable physics for interactive layout
    net.barnes_hut(spring_length=120, damping=0.8)

    for n, data in G.nodes(data=True):
        label = str(n)
        title = data.get('tooltip', label)
        size = max(6, int(data.get('size', 10)))
        color = data.get('color')
        if color is None:
            cat = data.get('category')
            if cat == 'personal':
                color = '#2ca02c'
            elif cat == 'corporate':
                color = '#d62728'
            elif cat == 'procedure':
                color = '#9467bd'
        net.add_node(str(n), label=label, title=title, size=size, color=color)

    for u, v, d in G.edges(data=True):
        w = int(d.get('weight', 1))
        net.add_edge(str(u), str(v), value=w, title=f"weight: {w}")

    html = net.generate_html(notebook=False)
    components.html(html, height=height, scrolling=True)

# ---- Advanced network helpers (metrics, normalization, export) ----
def _compute_centrality(G: nx.Graph, metric: str = 'degree') -> Dict[Any, float]:
    if G.number_of_nodes() == 0:
        return {}
    metric = metric.lower()
    if metric == 'degree':
        return {n: float(d) for n, d in G.degree()}
    if metric == 'betweenness':
        return nx.betweenness_centrality(G, normalized=True)
    if metric == 'eigenvector':
        try:
            return nx.eigenvector_centrality(G, max_iter=500)
        except nx.PowerIterationFailedConvergence:
            return nx.betweenness_centrality(G, normalized=True)
    if metric == 'pagerank':
        return nx.pagerank(G)
    # default
    return {n: float(d) for n, d in G.degree()}

def _scale_sizes(values: Dict[Any, float], min_size: int = 8, max_size: int = 40) -> Dict[Any, int]:
    if not values:
        return {}
    v = np.array(list(values.values()), dtype=float)
    v = (v - v.min()) / (np.ptp(v) + 1e-9)  # 0-1
    return {k: int(min_size + (max_size - min_size) * vv) for k, vv in zip(values.keys(), v)}

def _export_nodes_edges(G: nx.Graph) -> tuple[pd.DataFrame, pd.DataFrame]:
    nodes = []
    for n, d in G.nodes(data=True):
        nodes.append({'id': n, **{k: v for k, v in d.items() if k not in ['pos']}})
    edges = []
    for u, v, d in G.edges(data=True):
        rec = {'source': u, 'target': v}
        rec.update({k: v for k, v in d.items()})
        edges.append(rec)
    return pd.DataFrame(nodes), pd.DataFrame(edges)


def _cosine_normalized_weight(n_xy: int, n_x: int, n_y: int) -> float:
    # Safer than PMI for sparse small samples; 0..1 range roughly
    if n_x == 0 or n_y == 0:
        return 0.0
    return n_xy / np.sqrt(n_x * n_y)

# ---- Sankeyãƒ©ãƒ™ãƒ«æ”¹è¡Œãƒ˜ãƒ«ãƒ‘ ----
def _wrap_label(text: Any, width: int = 10, max_lines: int = 3) -> str:
    """Wrap long (JP) labels with newlines so Sankey node text doesn't overlap.
    width: number of characters per line (approx). max_lines: cap lines; add ellipsis when truncated.
    """
    if text is None:
        return ""
    s = str(text)
    if width <= 0:
        return s
    lines = [s[i:i+width] for i in range(0, len(s), width)]
    if max_lines and len(lines) > max_lines:
        lines = lines[:max_lines]
        if not lines[-1].endswith('â€¦'):
            lines[-1] = lines[-1] + 'â€¦'
    return "\n".join(lines)

# ---- Multi-value splitter for JP list-like fields ----
def _split_multi_values(val: Any) -> List[str]:
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return []
    s = str(val).strip()
    if s.lower() == 'nan' or s == '':
        return []
    for sep in ['\n', 'ã€', ',', 'ï¼Œ', ';', 'ï¼›', 'ãƒ»', '/', 'ï¼']:
        s = s.replace(sep, 'ã€')
    return [e.strip() for e in s.split('ã€') if e.strip()]

# --- Top-N + ãã®ä»– helper ---
def _topn_with_other(series: pd.Series, top: int = 8, other_label: str = 'ãã®ä»–') -> pd.DataFrame:
    """Return a DataFrame with columns [label, ä»¶æ•°] limited to top-
    categories and aggregate the rest into 'ãã®ä»–'. The first column name will be inferred later."""
    vc = series.value_counts()
    dfv = vc.reset_index()
    dfv.columns = ['label', 'ä»¶æ•°']
    if len(dfv) > top:
        keep = top - 1 if top >= 2 else 1
        top_df = dfv.iloc[:keep].copy()
        other_sum = dfv.iloc[keep:]['ä»¶æ•°'].sum()
        other_row = pd.DataFrame({'label': [other_label], 'ä»¶æ•°': [other_sum]})
        dfv = pd.concat([top_df, other_row], ignore_index=True)
    return dfv

# ---- æ‰‹ç¶šè©³ç´°ãƒ“ãƒ¥ãƒ¼ã®æç”»ãƒ˜ãƒ«ãƒ‘ ----
def _render_procedure_detail(proc_id: str, df: pd.DataFrame):
    """é¸æŠã—ãŸæ‰‹ç¶šIDã®è©³ç´°ã‚’è¡¨ç¤ºï¼ˆå…¨é …ç›®è¡¨ç¤ºç‰ˆï¼‰"""
    row = df[df['æ‰‹ç¶šID'] == proc_id]
    if row.empty:
        st.warning(f"æ‰‹ç¶šID {proc_id} ã®è©³ç´°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    r = row.iloc[0]
    
    # ã‚¿ã‚¤ãƒˆãƒ«éƒ¨
    st.title(f"ğŸ“„ {r.get('æ‰‹ç¶šå', '')}")
    st.caption(f"æ‰‹ç¶šID: {r.get('æ‰‹ç¶šID','')} | æ‰€ç®¡åºœçœåº: {r.get('æ‰€ç®¡åºœçœåº','')}")
    
    # ä¸»è¦æŒ‡æ¨™ã‚’ä¸Šéƒ¨ã«è¡¨ç¤º
    st.markdown("### ğŸ“Š ä¸»è¦æŒ‡æ¨™")
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.metric("æ‰‹ç¶šID", r.get('æ‰‹ç¶šID', 'â€”'))
    with col2:
        status = _normalize_label('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', r.get('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', ''))
        st.metric("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³", status if status else "â€”")
    with col3:
        st.metric("ç·æ‰‹ç¶šä»¶æ•°", f"{int(r.get('ç·æ‰‹ç¶šä»¶æ•°', 0) or 0):,}")
    with col4:
        st.metric("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°", f"{int(r.get('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°', 0) or 0):,}")
    with col5:
        rate = float(r.get('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡', 0) or 0)
        st.metric("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡", f"{rate:.1f}%")
    
    st.divider()
    
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§æƒ…å ±ã‚’æ•´ç†
    col_left, col_right = st.columns(2)
    
    with col_left:
        # åŸºæœ¬æƒ…å ±
        with st.expander("ğŸ›ï¸ **åŸºæœ¬æƒ…å ±**", expanded=True):
            items = [
                ("æ‰€ç®¡åºœçœåº", r.get('æ‰€ç®¡åºœçœåº', 'â€”')),
                ("æ‰‹ç¶šå", r.get('æ‰‹ç¶šå', 'â€”')),
                ("æ‰‹ç¶šé¡å‹", _normalize_label('æ‰‹ç¶šé¡å‹', r.get('æ‰‹ç¶šé¡å‹', 'â€”'))),
                ("æ‰‹ç¶šä¸»ä½“", r.get('æ‰‹ç¶šä¸»ä½“', 'â€”')),
                ("æ‰‹ç¶šã®å—ã‘æ‰‹", r.get('æ‰‹ç¶šã®å—ã‘æ‰‹', 'â€”')),
                ("çµŒç”±æ©Ÿé–¢", r.get('çµŒç”±æ©Ÿé–¢', 'â€”')),
                ("äº‹å‹™åŒºåˆ†", r.get('äº‹å‹™åŒºåˆ†', 'â€”')),
                ("åºœçœå…±é€šæ‰‹ç¶š", r.get('åºœçœå…±é€šæ‰‹ç¶š', 'â€”')),
            ]
            for label, value in items:
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.markdown(f"**{label}:**")
                with col2:
                    st.text(value if value else 'â€”')
        
        # æ³•ä»¤æƒ…å ±
        with st.expander("âš–ï¸ **æ³•ä»¤æƒ…å ±**", expanded=True):
            items = [
                ("æ³•ä»¤å", r.get('æ³•ä»¤å', 'â€”')),
                ("æ³•ä»¤ç•ªå·", r.get('æ³•ä»¤ç•ªå·', 'â€”')),
                ("æ ¹æ‹ æ¡é …å·", r.get('æ ¹æ‹ æ¡é …å·', 'â€”')),
            ]
            for label, value in items:
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.markdown(f"**{label}:**")
                with col2:
                    st.text(value if value else 'â€”')
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        with st.expander("ğŸ’» **ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±**", expanded=True):
            items = [
                ("ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ", r.get('æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)', 'â€”')),
                ("äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ", r.get('æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)', 'â€”')),
                ("å‡¦ç†æœŸé–“(ã‚ªãƒ³ãƒ©ã‚¤ãƒ³)", r.get('å‡¦ç†æœŸé–“(ã‚ªãƒ³ãƒ©ã‚¤ãƒ³)', 'â€”')),
                ("å‡¦ç†æœŸé–“(éã‚ªãƒ³ãƒ©ã‚¤ãƒ³)", r.get('å‡¦ç†æœŸé–“(éã‚ªãƒ³ãƒ©ã‚¤ãƒ³)', 'â€”')),
            ]
            for label, value in items:
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.markdown(f"**{label}:**")
                with col2:
                    st.text(value if value else 'â€”')
    
    with col_right:
        # ç”³è«‹ãƒ»æ›¸é¡æƒ…å ±
        with st.expander("ğŸ“ **ç”³è«‹ãƒ»æ›¸é¡æƒ…å ±**", expanded=True):
            items = [
                ("æœ¬äººç¢ºèªæ‰‹æ³•", r.get('ç”³è«‹ç­‰ã«ãŠã‘ã‚‹æœ¬äººç¢ºèªæ‰‹æ³•', 'â€”')),
                ("æå‡ºå…ˆæ©Ÿé–¢", r.get('ç”³è«‹ã‚’æå‡ºã™ã‚‹æ©Ÿé–¢', 'â€”')),
            ]
            for label, value in items:
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.markdown(f"**{label}:**")
                with col2:
                    st.text(value if value else 'â€”')
            
            # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã®é …ç›®
            if pd.notna(r.get('ç”³è«‹æ›¸ç­‰ã«è¨˜è¼‰ã•ã›ã‚‹æƒ…å ±')):
                st.markdown("**ç”³è«‹æ›¸è¨˜è¼‰æƒ…å ±:**")
                st.info(r.get('ç”³è«‹æ›¸ç­‰ã«è¨˜è¼‰ã•ã›ã‚‹æƒ…å ±', 'â€”'))
            
            if pd.notna(r.get('ç”³è«‹æ™‚ã«æ·»ä»˜ã•ã›ã‚‹æ›¸é¡')):
                st.markdown("**æ·»ä»˜æ›¸é¡:**")
                st.info(r.get('ç”³è«‹æ™‚ã«æ·»ä»˜ã•ã›ã‚‹æ›¸é¡', 'â€”'))
        
        # æ‰‹æ•°æ–™æƒ…å ±
        with st.expander("ğŸ’° **æ‰‹æ•°æ–™æƒ…å ±**", expanded=True):
            items = [
                ("ç´ä»˜æœ‰ç„¡", r.get('æ‰‹æ•°æ–™ç­‰ã®ç´ä»˜æœ‰ç„¡', 'â€”')),
                ("ç´ä»˜æ–¹æ³•", r.get('æ‰‹æ•°æ–™ç­‰ã®ç´ä»˜æ–¹æ³•', 'â€”')),
                ("å„ªé‡æªç½®", r.get('æ‰‹æ•°æ–™ç­‰ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç´ä»˜æ™‚ã®å„ªé‡æªç½®', 'â€”')),
            ]
            for label, value in items:
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.markdown(f"**{label}:**")
                with col2:
                    st.text(value if value else 'â€”')
        
        # ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆãƒ»å£«æ¥­
        with st.expander("ğŸŒŸ **ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆãƒ»å£«æ¥­**", expanded=True):
            if pd.notna(r.get('æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)')):
                st.markdown("**å€‹äººãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆ:**")
                st.info(r.get('æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)', 'â€”'))
            
            if pd.notna(r.get('æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)')):
                st.markdown("**æ³•äººãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆ:**")
                st.info(r.get('æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)', 'â€”'))
            
            if pd.notna(r.get('ç”³è«‹ã«é–¢é€£ã™ã‚‹å£«æ¥­')):
                st.markdown("**é–¢é€£å£«æ¥­:**")
                st.info(r.get('ç”³è«‹ã«é–¢é€£ã™ã‚‹å£«æ¥­', 'â€”'))
    
    # å…¨é …ç›®ãƒ‡ãƒ¼ã‚¿ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰
    with st.expander("ğŸ“‹ **å…¨38é …ç›®ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿**", expanded=False):
        # é‡è¦ãªé …ç›®ã‚’å…ˆé ­ã«é…ç½®
        important_cols = ['æ‰‹ç¶šID', 'æ‰‹ç¶šå', 'æ³•ä»¤å', 'æ‰€ç®¡åºœçœåº', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³']
        other_cols = [c for c in COLUMNS if c not in important_cols]
        ordered_cols = important_cols + other_cols
        
        data_dict = {}
        for col in ordered_cols:
            if col in r:
                value = r[col]
                if pd.notna(value) and str(value).strip():
                    data_dict[col] = str(value)
                else:
                    data_dict[col] = 'â€”'
        
        display_df = pd.DataFrame.from_dict(data_dict, orient='index', columns=['å€¤'])
        display_df.index.name = 'é …ç›®å'
        st.dataframe(display_df, use_container_width=True, height=400)
    
    # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    st.divider()
    csv_data = pd.DataFrame([r]).to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ã“ã®æ‰‹ç¶šã®æƒ…å ±ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_data,
        file_name=f"procedure_{proc_id}.csv",
        mime="text/csv"
    )

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("âš–ï¸ æ—¥æœ¬ã®æ³•ä»¤ã«åŸºã¥ãè¡Œæ”¿æ‰‹ç¶šç­‰ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.markdown("ç´„75,000ä»¶ã®æ³•ä»¤ãƒ»è¡Œæ”¿æ‰‹ç¶šãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ãƒ»åˆ†æ")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
    if not st.session_state.data_loaded:
        st.session_state.df = load_data()
        st.session_state.data_loaded = True
    
    df = st.session_state.df

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ“‹ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")

        # --- å³æ™‚é©ç”¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ---
        st.markdown("**åºœçœåº**")
        all_ministries = get_unique_values(df, 'æ‰€ç®¡åºœçœåº')
        # å»ºåˆ¶é †ï¼ˆæ­´å²çš„ãªçœåºè¨­ç«‹é †ï¼‰ã«ä¸¦ã¹æ›¿ãˆ
        # æ˜æ²»æœŸã‹ã‚‰ã®ä¼çµ±çš„çœåº â†’ æˆ¦å¾Œè¨­ç«‹ â†’ å¹³æˆå†ç·¨ â†’ è¿‘å¹´è¨­ç«‹ã®é †
        ministry_order = [
            "å®®å†…åº",           # 1869å¹´ï¼ˆæ˜æ²»2å¹´ï¼‰å®®å†…çœã¨ã—ã¦è¨­ç«‹
            "æ³•å‹™çœ",           # 1871å¹´ï¼ˆæ˜æ²»4å¹´ï¼‰å¸æ³•çœã¨ã—ã¦è¨­ç«‹
            "å¤–å‹™çœ",           # 1869å¹´ï¼ˆæ˜æ²»2å¹´ï¼‰å¤–å‹™çœè¨­ç«‹
            "è²¡å‹™çœ",           # 1869å¹´ï¼ˆæ˜æ²»2å¹´ï¼‰å¤§è”µçœã¨ã—ã¦è¨­ç«‹ã€2001å¹´è²¡å‹™çœã«
            "æ–‡éƒ¨ç§‘å­¦çœ",       # 1871å¹´ï¼ˆæ˜æ²»4å¹´ï¼‰æ–‡éƒ¨çœã¨ã—ã¦è¨­ç«‹ã€2001å¹´æ–‡éƒ¨ç§‘å­¦çœã«
            "è¾²æ—æ°´ç”£çœ",       # 1881å¹´ï¼ˆæ˜æ²»14å¹´ï¼‰è¾²å•†å‹™çœã¨ã—ã¦è¨­ç«‹
            "çµŒæ¸ˆç”£æ¥­çœ",       # 1881å¹´ï¼ˆæ˜æ²»14å¹´ï¼‰è¾²å•†å‹™çœã€1949å¹´é€šå•†ç”£æ¥­çœã€2001å¹´çµŒæ¸ˆç”£æ¥­çœã«
            "å›½åœŸäº¤é€šçœ",       # 1874å¹´ï¼ˆæ˜æ²»7å¹´ï¼‰å†…å‹™çœã€2001å¹´å›½åœŸäº¤é€šçœã«
            "ä¼šè¨ˆæ¤œæŸ»é™¢",       # 1880å¹´ï¼ˆæ˜æ²»13å¹´ï¼‰ä¼šè¨ˆæ¤œæŸ»é™¢è¨­ç«‹
            "äººäº‹é™¢",           # 1948å¹´ï¼ˆæ˜­å’Œ23å¹´ï¼‰äººäº‹é™¢è¨­ç«‹
            "å†…é–£å®˜æˆ¿",         # 1947å¹´ï¼ˆæ˜­å’Œ22å¹´ï¼‰å†…é–£å®˜æˆ¿è¨­ç«‹
            "ç·å‹™çœ",           # 1960å¹´ï¼ˆæ˜­å’Œ35å¹´ï¼‰è‡ªæ²»çœã€2001å¹´ç·å‹™çœã«
            "åšç”ŸåŠ´åƒçœ",       # 1938å¹´ï¼ˆæ˜­å’Œ13å¹´ï¼‰åšç”Ÿçœã€2001å¹´åšç”ŸåŠ´åƒçœã«
            "é˜²è¡›çœ",           # 1954å¹´ï¼ˆæ˜­å’Œ29å¹´ï¼‰é˜²è¡›åºã€2007å¹´é˜²è¡›çœã«
            "å›½å®¶å…¬å®‰å§”å“¡ä¼š",   # 1954å¹´ï¼ˆæ˜­å’Œ29å¹´ï¼‰å›½å®¶å…¬å®‰å§”å“¡ä¼šè¨­ç«‹
            "å…¬æ­£å–å¼•å§”å“¡ä¼š",   # 1947å¹´ï¼ˆæ˜­å’Œ22å¹´ï¼‰å…¬æ­£å–å¼•å§”å“¡ä¼šè¨­ç«‹
            "ç’°å¢ƒçœ",           # 1971å¹´ï¼ˆæ˜­å’Œ46å¹´ï¼‰ç’°å¢ƒåºã€2001å¹´ç’°å¢ƒçœã«
            "å†…é–£åºœ",           # 2001å¹´ï¼ˆå¹³æˆ13å¹´ï¼‰å†…é–£åºœè¨­ç«‹
            "é‡‘èåº",           # 1998å¹´ï¼ˆå¹³æˆ10å¹´ï¼‰é‡‘èç›£ç£åºã€2000å¹´é‡‘èåºã«
            "æ¶ˆè²»è€…åº",         # 2009å¹´ï¼ˆå¹³æˆ21å¹´ï¼‰æ¶ˆè²»è€…åºè¨­ç«‹
            "å¾©èˆˆåº",           # 2012å¹´ï¼ˆå¹³æˆ24å¹´ï¼‰å¾©èˆˆåºè¨­ç«‹
            "å€‹äººæƒ…å ±ä¿è­·å§”å“¡ä¼š", # 2016å¹´ï¼ˆå¹³æˆ28å¹´ï¼‰å€‹äººæƒ…å ±ä¿è­·å§”å“¡ä¼šè¨­ç«‹
            "ã‚«ã‚¸ãƒç®¡ç†å§”å“¡ä¼š", # 2020å¹´ï¼ˆä»¤å’Œ2å¹´ï¼‰ã‚«ã‚¸ãƒç®¡ç†å§”å“¡ä¼šè¨­ç«‹
            "ãƒ‡ã‚¸ã‚¿ãƒ«åº"        # 2021å¹´ï¼ˆä»¤å’Œ3å¹´ï¼‰ãƒ‡ã‚¸ã‚¿ãƒ«åºè¨­ç«‹
        ]
        # é †åºä»˜ããƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã ã‘ï¼‰
        ordered_ministries = [m for m in ministry_order if m in all_ministries]
        # ãƒªã‚¹ãƒˆã«ãªã„åºœçœåºã‚’è¿½åŠ 
        remaining = [m for m in all_ministries if m not in ordered_ministries]
        ordered_ministries.extend(sorted(remaining))
        
        selected_ministries = st.multiselect(
            "åºœçœåºã‚’é¸æŠ",
            ordered_ministries,
            key="ministry_filter",
            label_visibility="collapsed",
            help=FIELD_DEFS.get('æ‰€ç®¡åºœçœåº', '')
        )

        st.markdown("**ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³**")
        all_statuses = get_unique_values(df, 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³')
        selected_statuses = st.multiselect(
            "çŠ¶æ³ã‚’é¸æŠ",
            all_statuses,
            key="status_filter",
            label_visibility="collapsed",
            help=FIELD_DEFS.get('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', '')
        )

        st.markdown("**æ‰‹ç¶šé¡å‹**")
        all_types = get_unique_values(df, 'æ‰‹ç¶šé¡å‹')
        selected_types = st.multiselect(
            "é¡å‹ã‚’é¸æŠ",
            all_types,
            key="type_filter",
            label_visibility="collapsed",
            help=FIELD_DEFS.get('æ‰‹ç¶šé¡å‹', '')
        )

        st.markdown("**æ‰‹ç¶šä¸»ä½“**")
        all_actors = get_unique_values(df, 'æ‰‹ç¶šä¸»ä½“') if 'æ‰‹ç¶šä¸»ä½“' in df.columns else []
        selected_actors = st.multiselect(
            "ä¸»ä½“ã‚’é¸æŠ",
            all_actors,
            key="actor_filter",
            label_visibility="collapsed",
            help=FIELD_DEFS.get('æ‰‹ç¶šä¸»ä½“', '')
        )

        st.markdown("**æ‰‹ç¶šã®å—ã‘æ‰‹**")
        all_receivers = get_unique_values(df, 'æ‰‹ç¶šã®å—ã‘æ‰‹') if 'æ‰‹ç¶šã®å—ã‘æ‰‹' in df.columns else []
        selected_receivers = st.multiselect(
            "å—ã‘æ‰‹ã‚’é¸æŠ",
            all_receivers,
            key="receiver_filter",
            label_visibility="collapsed",
            help=FIELD_DEFS.get('æ‰‹ç¶šã®å—ã‘æ‰‹', '')
        )

        st.markdown("**äº‹å‹™åŒºåˆ†**")
        all_office_types = get_unique_values(df, 'äº‹å‹™åŒºåˆ†') if 'äº‹å‹™åŒºåˆ†' in df.columns else []
        selected_office_types = st.multiselect(
            "äº‹å‹™åŒºåˆ†ã‚’é¸æŠ",
            all_office_types,
            key="office_type_filter",
            label_visibility="collapsed",
            help=FIELD_DEFS.get('äº‹å‹™åŒºåˆ†', '')
        )

        st.markdown("**åºœçœå…±é€šæ‰‹ç¶š**")
        all_common = get_unique_values(df, 'åºœçœå…±é€šæ‰‹ç¶š') if 'åºœçœå…±é€šæ‰‹ç¶š' in df.columns else []
        selected_common = st.multiselect(
            "å…±é€šæ‰‹ç¶šã®ç¨®åˆ¥ã‚’é¸æŠ",
            all_common,
            key="common_filter",
            label_visibility="collapsed",
            help=FIELD_DEFS.get('åºœçœå…±é€šæ‰‹ç¶š', '')
        )

        st.markdown("**æ‰‹ç¶šä»¶æ•°ç¯„å›²**")
        count_ranges = [
            "100ä¸‡ä»¶ä»¥ä¸Š",
            "10ä¸‡ä»¶ä»¥ä¸Š100ä¸‡ä»¶æœªæº€",
            "1ä¸‡ä»¶ä»¥ä¸Š10ä¸‡ä»¶æœªæº€",
            "1000ä»¶ä»¥ä¸Š1ä¸‡ä»¶æœªæº€",
            "100ä»¶ä»¥ä¸Š1000ä»¶æœªæº€",
            "10ä»¶ä»¥ä¸Š100ä»¶æœªæº€",
            "1ä»¶ä»¥ä¸Š10ä»¶æœªæº€",
            "0ä»¶ã‚‚ã—ãã¯ä¸æ˜"
        ]
        selected_count_ranges = st.multiselect(
            "æ‰‹ç¶šä»¶æ•°ç¯„å›²ã‚’é¸æŠ",
            count_ranges,
            key="count_range_filter",
            label_visibility="collapsed",
            help="ç·æ‰‹ç¶šä»¶æ•°ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿"
        )

        # å³æ™‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        filtered_df = filter_dataframe(
            df,
            selected_ministries,
            selected_statuses,
            selected_types,
            selected_receivers,
            actors=selected_actors,
            receivers=selected_receivers,
            office_types=selected_office_types,
            is_common=selected_common,
            count_ranges=selected_count_ranges,
        )

        with st.expander("â„¹ï¸ é …ç›®å®šç¾©ï¼ˆæŠœç²‹ï¼‰"):
            for k in ["æ‰‹ç¶šé¡å‹", "æ‰‹ç¶šä¸»ä½“", "æ‰‹ç¶šã®å—ã‘æ‰‹", "äº‹å‹™åŒºåˆ†", "åºœçœå…±é€šæ‰‹ç¶š", "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³"]:
                if k in FIELD_DEFS:
                    st.markdown(f"**{k}** â€” {FIELD_DEFS[k]}")
    
    # è©³ç´°ç”»é¢ã®è¡¨ç¤ºï¼ˆæ¤œç´¢çµæœã‹ã‚‰é·ç§»ï¼‰
    if st.session_state.get('show_detail', False) and st.session_state.get('selected_procedure_id'):
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³
        if st.button("â† æ¤œç´¢çµæœã«æˆ»ã‚‹"):
            st.session_state['show_detail'] = False
            st.session_state['selected_procedure_id'] = None
            st.rerun()
        
        # è©³ç´°è¡¨ç¤º
        _render_procedure_detail(st.session_state['selected_procedure_id'], df)
        return
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š æ¦‚è¦çµ±è¨ˆ", 
        "âš–ï¸ æ³•ä»¤åˆ¥åˆ†æ", 
        "ğŸ¢ åºœçœåºåˆ¥åˆ†æ",
        "ğŸ’» ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ åˆ†æ",
        "ğŸ“ ç”³è«‹æ–‡æ›¸åˆ†æ",
        "ğŸ” æ³•ä»¤ãƒ»æ‰‹ç¶šæ¤œç´¢",
        "ğŸ¤– é«˜åº¦ãªåˆ†æ(Î²)"
    ])
    
    with tab1:
        st.header("ğŸ“Š æ¦‚è¦çµ±è¨ˆ")

        # KPIã‚«ãƒ¼ãƒ‰ï¼ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ã‚’ç¢ºèªã—ã¤ã¤å®‰å…¨ã«ç®—å‡ºï¼‰
        col1, col2, col3, col4 = st.columns(4)
        n_total = len(filtered_df)
        with col1:
            delta_val = n_total - len(df)
            st.metric("ç·æ‰‹ç¶šæ•°", f"{n_total:,}", delta=(f"{delta_val:+,}" if delta_val != 0 else None))
        with col2:
            total_proc_count = filtered_df['ç·æ‰‹ç¶šä»¶æ•°'].sum() if 'ç·æ‰‹ç¶šä»¶æ•°' in filtered_df.columns else 0
            st.metric("ç·æ‰‹ç¶šä»¶æ•°", f"{int(total_proc_count):,}")
        with col3:
            online_count = filtered_df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'].sum() if 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°' in filtered_df.columns else 0
            st.metric("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°", f"{int(online_count):,}")
        with col4:
            online_rate = (online_count / total_proc_count * 100) if total_proc_count else 0
            st.metric("ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡", f"{online_rate:.1f}%")

        # ã‚°ãƒ©ãƒ•
        col1, col2 = st.columns(2)

        with col1:
            # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³ã®å††ã‚°ãƒ©ãƒ•ï¼ˆæ­£è¦åŒ–é©ç”¨ï¼‰
            status_counts = normalized_counts(filtered_df, 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³')
            if status_counts.sum() > 0:
                status_df = status_counts.reset_index()
                status_df.columns = ['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', 'ä»¶æ•°']
                fig_pie = px.pie(
                    status_df,
                    values='ä»¶æ•°',
                    names='ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³',
                    title="ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³",
                    hole=0.4
                )
                st.plotly_chart(fig_pie, use_container_width=True)
            else:
                st.info("è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰")

        with col2:
            # æ‰‹ç¶šé¡å‹ã®æ£’ã‚°ãƒ©ãƒ•ï¼ˆæ­£è¦åŒ–é©ç”¨ï¼‰
            type_counts = normalized_counts(filtered_df, 'æ‰‹ç¶šé¡å‹', 'æ‰‹ç¶šé¡å‹')
            # å®šç¾©é †ãŒã‚ã‚Œã°head(10)å¾Œã§ã‚‚OKã€ãªã‘ã‚Œã°é »åº¦ä¸Šä½10
            if 'æ‰‹ç¶šé¡å‹' in OPTION_ORDERS:
                type_counts = type_counts.head(10)
            else:
                type_counts = type_counts.head(10)
            if type_counts.sum() > 0:
                type_df = type_counts.reset_index()
                type_df.columns = ['æ‰‹ç¶šé¡å‹', 'ä»¶æ•°']
                # é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆã‚°ãƒ©ãƒ•ä¸Šã§ä¸Šã‹ã‚‰ä¸‹ã¸å¤šã„é †ã«è¡¨ç¤ºï¼‰
                type_df = type_df.sort_values('ä»¶æ•°', ascending=True)
                fig_bar = px.bar(
                    type_df,
                    x='ä»¶æ•°',
                    y='æ‰‹ç¶šé¡å‹',
                    orientation='h',
                    title="æ‰‹ç¶šé¡å‹TOP10",
                    labels={'ä»¶æ•°': 'ä»¶æ•°', 'æ‰‹ç¶šé¡å‹': 'æ‰‹ç¶šé¡å‹'}
                )
                st.plotly_chart(fig_bar, use_container_width=True)
            else:
                st.info("è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰")
        
        # æ‰‹ç¶šä¸€è¦§ã®è¡¨ç¤º
        st.subheader("ğŸ“‹ æ‰‹ç¶šä¸€è¦§")
        
        # è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠ
        display_columns = [
            'æ‰‹ç¶šID', 'æ‰‹ç¶šå', 'æ‰€ç®¡åºœçœåº', 'æ‰‹ç¶šé¡å‹',
            'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³', 'ç·æ‰‹ç¶šä»¶æ•°', 
            'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡'
        ]
        
        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿é¸æŠ
        available_columns = [col for col in display_columns if col in filtered_df.columns]
        
        # é¸æŠå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
        selection = st.dataframe(
            filtered_df[available_columns].reset_index(drop=True),
            use_container_width=True,
            height=400,
            selection_mode="single-row",
            on_select="rerun"
        )
        
        # é¸æŠã•ã‚ŒãŸè¡ŒãŒã‚ã‚‹å ´åˆã€è©³ç´°ã‚’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã§è¡¨ç¤º
        if selection and selection.selection.rows:
            selected_idx = selection.selection.rows[0]
            selected_proc = filtered_df.iloc[selected_idx]
            
            @st.dialog(f"ğŸ“„ æ‰‹ç¶šè©³ç´°: {selected_proc['æ‰‹ç¶šå'][:30]}...", width="large")
            def show_procedure_modal():
                _render_procedure_detail(selected_proc['æ‰‹ç¶šID'], df)
            
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info(f"é¸æŠã•ã‚ŒãŸæ‰‹ç¶š: {selected_proc['æ‰‹ç¶šå']}")
            with col2:
                if st.button("ğŸ“„ è©³ç´°ã‚’è¡¨ç¤º", key="overview_detail_btn"):
                    show_procedure_modal()
        
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        csv_data = df_to_csv_bytes(filtered_df[available_columns])
        st.download_button(
            label="ğŸ“¥ æ‰‹ç¶šä¸€è¦§ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name="procedures_list.csv",
            mime="text/csv"
        )
    
    with tab2:
        st.header("âš–ï¸ æ³•ä»¤åˆ¥åˆ†æ")
        
        # æ³•ä»¤åˆ¥ã®æ‰‹ç¶šæ•°
        st.subheader("ğŸ“š æ³•ä»¤åˆ¥æ‰‹ç¶šæ•°ï¼ˆTOP20ï¼‰")
        law_counts = filtered_df['æ³•ä»¤å'].value_counts().head(20)
        if len(law_counts) > 0:
            # é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆå°‘ãªã„é †ã‹ã‚‰å¤šã„é †ã¸ã€ã‚°ãƒ©ãƒ•ä¸Šã§ä¸Šã‹ã‚‰ä¸‹ã¸å¤šã„é †ã«è¡¨ç¤ºï¼‰
            law_counts = law_counts.sort_values(ascending=True)
            fig_law = px.bar(
                x=law_counts.values,
                y=law_counts.index,
                orientation='h',
                title="æ³•ä»¤åˆ¥æ‰‹ç¶šæ•°",
                labels={'x': 'æ‰‹ç¶šæ•°', 'y': 'æ³•ä»¤å'}
            )
            fig_law.update_layout(height=600)
            st.plotly_chart(fig_law, use_container_width=True)
        
        # æ³•ä»¤åˆ¥ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³
        st.subheader("ğŸ“Š ä¸»è¦æ³•ä»¤ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³")
        
        # æ‰‹ç¶šæ•°ãŒå¤šã„æ³•ä»¤TOP10ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³
        top_laws = filtered_df['æ³•ä»¤å'].value_counts().head(10).index
        law_online_data = []
        
        for law in top_laws:
            law_df = filtered_df[filtered_df['æ³•ä»¤å'] == law]
            total = len(law_df)
            online = len(law_df[law_df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³'].str.contains('å®Ÿæ–½æ¸ˆ', na=False)])
            rate = (online / total * 100) if total > 0 else 0
            law_online_data.append({
                'æ³•ä»¤å': law[:30] + ('...' if len(law) > 30 else ''),
                'æ‰‹ç¶šæ•°': total,
                'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–æ¸ˆ': online,
                'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡': rate
            })
        
        law_online_df = pd.DataFrame(law_online_data)
        
        fig_law_online = px.scatter(
            law_online_df,
            x='æ‰‹ç¶šæ•°',
            y='ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡',
            size='æ‰‹ç¶šæ•°',
            hover_data=['æ³•ä»¤å', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–æ¸ˆ'],
            title="ä¸»è¦æ³•ä»¤ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡",
            labels={'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡': 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ (%)'}
        )
        st.plotly_chart(fig_law_online, use_container_width=True)
        
        # æ³•ä»¤åˆ¥è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
        st.subheader("ğŸ“‹ æ³•ä»¤åˆ¥è©³ç´°çµ±è¨ˆ")
        st.dataframe(law_online_df.sort_values('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡', ascending=False), use_container_width=True)
        
        # æ³•ä»¤ç•ªå·ã®å½¢å¼åˆ¥åˆ†æ
        st.subheader("âš–ï¸ æ³•ä»¤ç¨®åˆ¥ã®åˆ†æ")
        
        # æ³•å¾‹ã€æ”¿ä»¤ã€çœä»¤ãªã©ã®åˆ†é¡
        def classify_law_type(law_number):
            if pd.isna(law_number):
                return 'ä¸æ˜'
            law_str = str(law_number)
            if 'æ³•å¾‹' in law_str:
                return 'æ³•å¾‹'
            elif 'æ”¿ä»¤' in law_str:
                return 'æ”¿ä»¤'
            elif 'çœä»¤' in law_str or 'è¦å‰‡' in law_str:
                return 'çœä»¤ãƒ»è¦å‰‡'
            elif 'å‘Šç¤º' in law_str:
                return 'å‘Šç¤º'
            elif 'é€šé”' in law_str or 'é€šçŸ¥' in law_str:
                return 'é€šé”ãƒ»é€šçŸ¥'
            else:
                return 'ãã®ä»–'
        
        filtered_df['æ³•ä»¤ç¨®åˆ¥'] = filtered_df['æ³•ä»¤ç•ªå·'].apply(classify_law_type)
        law_type_counts = filtered_df['æ³•ä»¤ç¨®åˆ¥'].value_counts()
        
        col1, col2 = st.columns(2)
        with col1:
            fig_law_type = px.pie(
                values=law_type_counts.values,
                names=law_type_counts.index,
                title="æ³•ä»¤ç¨®åˆ¥ã®åˆ†å¸ƒ",
                hole=0.4
            )
            st.plotly_chart(fig_law_type, use_container_width=True)
        
        with col2:
            # æ³•ä»¤ç¨®åˆ¥ã”ã¨ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡
            law_type_online = filtered_df.groupby('æ³•ä»¤ç¨®åˆ¥').agg({
                'æ‰‹ç¶šID': 'count',
                'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡': 'mean'
            }).reset_index()
            law_type_online.columns = ['æ³•ä»¤ç¨®åˆ¥', 'æ‰‹ç¶šæ•°', 'å¹³å‡ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡']
            
            fig_law_type_online = px.bar(
                law_type_online,
                x='æ³•ä»¤ç¨®åˆ¥',
                y='å¹³å‡ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡',
                title="æ³•ä»¤ç¨®åˆ¥ã”ã¨ã®å¹³å‡ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡",
                labels={'å¹³å‡ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡': 'å¹³å‡ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ (%)'}
            )
            st.plotly_chart(fig_law_type_online, use_container_width=True)
    
    with tab3:
        st.header("ğŸ¢ åºœçœåºåˆ¥åˆ†æ")
        
        # åºœçœåºåˆ¥ã®æ‰‹ç¶šæ•°
        ministry_counts = filtered_df['æ‰€ç®¡åºœçœåº'].value_counts().head(20)
        fig_ministry = px.bar(
            x=ministry_counts.index,
            y=ministry_counts.values,
            title="åºœçœåºåˆ¥æ‰‹ç¶šæ•°ï¼ˆTOP20ï¼‰",
            labels={'x': 'åºœçœåº', 'y': 'æ‰‹ç¶šæ•°'}
        )
        fig_ministry.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig_ministry, use_container_width=True)
        
        # åºœçœåºåˆ¥ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡
        ministry_stats = filtered_df.groupby('æ‰€ç®¡åºœçœåº').agg({
            'æ‰‹ç¶šID': 'count',
            'ç·æ‰‹ç¶šä»¶æ•°': 'sum',
            'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°': 'sum'
        }).reset_index()
        ministry_stats.columns = ['åºœçœåº', 'æ‰‹ç¶šæ•°', 'ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°']
        ministry_stats['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡'] = (
            ministry_stats['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'] / ministry_stats['ç·æ‰‹ç¶šä»¶æ•°'] * 100
        ).round(2)
        ministry_stats = ministry_stats[ministry_stats['ç·æ‰‹ç¶šä»¶æ•°'] > 0]
        ministry_stats = ministry_stats.sort_values('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡', ascending=False).head(20)
        
        fig_ministry_online = px.scatter(
            ministry_stats,
            x='æ‰‹ç¶šæ•°',
            y='ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡',
            size='ç·æ‰‹ç¶šä»¶æ•°',
            hover_data=['åºœçœåº', 'ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'],
            title="åºœçœåºåˆ¥ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·æ‰‹ç¶šä»¶æ•°ï¼‰",
            labels={'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡': 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ (%)'}
        )
        st.plotly_chart(fig_ministry_online, use_container_width=True)
        
        # åºœçœåºåˆ¥è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
        st.subheader("ğŸ“‹ åºœçœåºåˆ¥è©³ç´°çµ±è¨ˆ")
        st.dataframe(
            ministry_stats.sort_values('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡', ascending=False),
            use_container_width=True
        )
    
    with tab4:
        st.header("ğŸ’» ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ åˆ†æ")
        
        # ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç”³è«‹ï¼‰ã®åˆ†æ
        st.subheader("ğŸ“Š ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç”¨çŠ¶æ³")
        
        # ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
        system_df = filtered_df[filtered_df['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)'].notna()].copy()
        
        if len(system_df) > 0:
            # ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®æ‰‹ç¶šæ•°ã‚’é›†è¨ˆ
            system_counts = system_df['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)'].value_counts().head(20)
            # é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆã‚°ãƒ©ãƒ•ä¸Šã§ä¸Šã‹ã‚‰ä¸‹ã¸å¤šã„é †ã«è¡¨ç¤ºï¼‰
            system_counts = system_counts.sort_values(ascending=True)
            
            # ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ åˆ¥æ‰‹ç¶šæ•°ã®æ£’ã‚°ãƒ©ãƒ•
            fig_system = px.bar(
                x=system_counts.values,
                y=system_counts.index,
                orientation='h',
                title="ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ åˆ¥æ‰‹ç¶šæ•°ï¼ˆTOP20ï¼‰",
                labels={'x': 'æ‰‹ç¶šæ•°', 'y': 'ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ '}
            )
            st.plotly_chart(fig_system, use_container_width=True)
            
            # ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡
            system_stats = system_df.groupby('æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)').agg({
                'æ‰‹ç¶šID': 'count',
                'ç·æ‰‹ç¶šä»¶æ•°': 'sum',
                'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°': 'sum'
            }).reset_index()
            system_stats.columns = ['ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ', 'æ‰‹ç¶šæ•°', 'ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°']
            system_stats['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡'] = (
                system_stats['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'] / system_stats['ç·æ‰‹ç¶šä»¶æ•°'] * 100
            ).round(2)
            system_stats = system_stats[system_stats['ç·æ‰‹ç¶šä»¶æ•°'] > 0]
            system_stats = system_stats.sort_values('ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡', ascending=False).head(20)
            
            # æ•£å¸ƒå›³ï¼šã‚·ã‚¹ãƒ†ãƒ åˆ¥ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡
            fig_system_scatter = px.scatter(
                system_stats,
                x='æ‰‹ç¶šæ•°',
                y='ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡',
                size='ç·æ‰‹ç¶šä»¶æ•°',
                hover_data=['ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ', 'ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'],
                title="ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·æ‰‹ç¶šä»¶æ•°ï¼‰",
                labels={'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡': 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡ (%)'}
            )
            st.plotly_chart(fig_system_scatter, use_container_width=True)
            
            # ã‚·ã‚¹ãƒ†ãƒ åˆ¥è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«
            st.subheader("ğŸ“‹ ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ åˆ¥è©³ç´°çµ±è¨ˆ")
            st.dataframe(
                system_stats[['ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ', 'æ‰‹ç¶šæ•°', 'ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡']],
                use_container_width=True
            )
        else:
            st.info("ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
        # äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆ†æ
        st.subheader("ğŸ–¥ï¸ äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç”¨çŠ¶æ³")
        
        # äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
        process_system_df = filtered_df[filtered_df['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)'].notna()].copy()
        
        if len(process_system_df) > 0:
            # ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã®æ‰‹ç¶šæ•°ã‚’é›†è¨ˆ
            process_system_counts = process_system_df['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)'].value_counts().head(20)
            # é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆã‚°ãƒ©ãƒ•ä¸Šã§ä¸Šã‹ã‚‰ä¸‹ã¸å¤šã„é †ã«è¡¨ç¤ºï¼‰
            process_system_counts = process_system_counts.sort_values(ascending=True)
            
            # äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆ¥æ‰‹ç¶šæ•°ã®æ£’ã‚°ãƒ©ãƒ•
            fig_process_system = px.bar(
                x=process_system_counts.values,
                y=process_system_counts.index,
                orientation='h',
                title="äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆ¥æ‰‹ç¶šæ•°ï¼ˆTOP20ï¼‰",
                labels={'x': 'æ‰‹ç¶šæ•°', 'y': 'äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ '}
            )
            st.plotly_chart(fig_process_system, use_container_width=True)
            
            # ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ã¨äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®çµ„ã¿åˆã‚ã›åˆ†æ
            st.subheader("ğŸ”„ ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ã¨äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®é€£æº")
            
            # ä¸¡æ–¹ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿
            both_systems = filtered_df[
                (filtered_df['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)'].notna()) & 
                (filtered_df['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)'].notna())
            ].copy()
            
            if len(both_systems) > 0:
                # ã‚·ã‚¹ãƒ†ãƒ çµ„ã¿åˆã‚ã›ã®é›†è¨ˆ
                system_combo = both_systems.groupby(['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)', 'æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)']).size().reset_index(name='æ‰‹ç¶šæ•°')
                system_combo = system_combo.sort_values('æ‰‹ç¶šæ•°', ascending=False).head(20)

                # ãƒãƒ¼ãƒ‰é›†åˆã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¸€åº¦ã ã‘æ§‹ç¯‰
                nodes = list(pd.unique(pd.concat([
                    system_combo['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)'], system_combo['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)']
                ], ignore_index=True)))
                idx = {name: i for i, name in enumerate(nodes)}

                sources = [idx[s] for s in system_combo['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (ç”³è«‹)']]
                targets = [idx[t] for t in system_combo['æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ (äº‹å‹™å‡¦ç†)']]
                values  = system_combo['æ‰‹ç¶šæ•°'].tolist()

                # å¯èª­æ€§å‘ä¸Šï¼šãƒ©ãƒ™ãƒ«æ”¹è¡Œãƒ»ãƒãƒ¼ãƒ‰é–“éš”ãƒ»å¤ªã•ãƒ»å›³ã‚µã‚¤ã‚ºã‚’èª¿æ•´
                labels_raw = nodes
                labels_wrapped = [_wrap_label(n, width=10, max_lines=3) for n in labels_raw]

                sankey = go.Sankey(
                    arrangement='snap',
                    node=dict(
                        pad=24,
                        thickness=24,
                        line=dict(color="rgba(0,0,0,0.25)", width=0.5),
                        label=labels_wrapped,
                        hovertemplate="%{label}<extra></extra>",
                    ),
                    link=dict(
                        source=sources,
                        target=targets,
                        value=values,
                        color='rgba(150,150,150,0.25)',
                        hovertemplate="%{source.label} â†’ %{target.label}<br>æ‰‹ç¶šæ•°: %{value}<extra></extra>",
                    )
                )

                fig_sankey = go.Figure(data=[sankey])
                fig_sankey.update_layout(
                    title="ç”³è«‹ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®é€£æºï¼ˆTOP20ï¼‰",
                    font=dict(size=12),
                    hoverlabel=dict(font_size=12),
                    margin=dict(l=10, r=10, t=40, b=10),
                    height=800
                )
                st.plotly_chart(fig_sankey, use_container_width=True)

                st.caption("â€» ãƒãƒ¼ãƒ‰åã¯10æ–‡å­—ã”ã¨ã«æ”¹è¡Œãƒ»æœ€å¤§3è¡Œã§çœç•¥è¡¨ç¤ºã€‚ãƒ›ãƒãƒ¼ã§å…¨åã‚’ç¢ºèªã§ãã¾ã™ã€‚")

                st.dataframe(
                    system_combo,
                    use_container_width=True
                )
            else:
                st.info("ä¸¡ã‚·ã‚¹ãƒ†ãƒ ã®é€£æºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.info("äº‹å‹™å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    # --- æ·»ä»˜æ›¸é¡åˆ†æã‚¿ãƒ– (tab5) ---
    with tab5:
        st.header("ğŸ“ ç”³è«‹æ–‡æ›¸åˆ†æ")
        st.caption("æ·»ä»˜æ›¸é¡ã‚„æå‡ºæ–¹å¼ãƒ»é›»å­ç½²åã®åˆ†å¸ƒã€æ‰‹ç¶šé¡å‹ã¨ã®é–¢ä¿‚ã‚’åˆ†æã—ã¾ã™ã€‚")

        att_col = 'ç”³è«‹æ™‚ã«æ·»ä»˜ã•ã›ã‚‹æ›¸é¡'
        remove_col = 'æ·»ä»˜æ›¸é¡ç­‰æå‡ºã®æ’¤å»ƒ/çœç•¥çŠ¶æ³'
        method_col = 'æ·»ä»˜æ›¸é¡ç­‰ã®æå‡ºæ–¹æ³•'
        sign_col = 'æ·»ä»˜æ›¸é¡ç­‰ã¸ã®é›»å­ç½²å'

        cols_exist = [c for c in [att_col, remove_col, method_col, sign_col] if c in filtered_df.columns]
        if not cols_exist:
            st.info("æ·»ä»˜æ›¸é¡ã«é–¢ã™ã‚‹åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            # --- ä¸Šæ®µï¼šã‚µãƒãƒªãƒ¼ï¼ˆå††ã‚°ãƒ©ãƒ•Ã—3ï¼‰ ---
            dist_cols = []
            if remove_col in filtered_df.columns:
                dist_cols.append((remove_col, 'æ’¤å»ƒ/çœç•¥çŠ¶æ³ã®åˆ†å¸ƒ'))
            if method_col in filtered_df.columns:
                dist_cols.append((method_col, 'æå‡ºæ–¹æ³•ã®åˆ†å¸ƒ'))
            if sign_col in filtered_df.columns:
                dist_cols.append((sign_col, 'é›»å­ç½²åã®è¦å¦ã®åˆ†å¸ƒ'))

            if dist_cols:
                pie_top = st.slider("åˆ†å¸ƒã‚°ãƒ©ãƒ•ã®ã‚«ãƒ†ã‚´ãƒªä¸Šé™ (Top N)", 5, 15, 8, step=1, help="ã‚«ãƒ†ã‚´ãƒªãŒå¤šã„å ´åˆã¯ä¸Šä½ã®ã¿è¡¨ç¤ºã—ã€æ®‹ã‚Šã¯ã€ãã®ä»–ã€ã«ã¾ã¨ã‚ã¾ã™")
                for cname, title_txt in dist_cols:
                    series = filtered_df[cname].dropna().astype(str)
                    series = series[series.str.strip() != '']
                    if len(series) > 0:
                        dfv = _topn_with_other(series, top=pie_top, other_label='ãã®ä»–')
                        dfv[cname] = dfv['label'].map(lambda s: _wrap_label(s, width=10, max_lines=2))
                        fig = px.pie(dfv, values='ä»¶æ•°', names=cname, title=title_txt, hole=0.4)
                        fig.update_layout(
                            margin=dict(l=0, r=0, t=40, b=0),
                            height=400,
                            legend=dict(font=dict(size=11), tracegroupgap=4)
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info(f"'{cname}' ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            st.divider()

            # --- ä¸­æ®µï¼šæ·»ä»˜æ›¸é¡ãƒˆãƒƒãƒ— ---
            st.subheader("ğŸ“Œ æ·»ä»˜æ›¸é¡ã®é »å‡ºï¼ˆTOP Nï¼‰")
            if att_col in filtered_df.columns:
                att_series = filtered_df[att_col].dropna().apply(_split_multi_values).explode().astype(str)
                att_series = att_series[att_series.str.strip() != '']
                if len(att_series) > 0:
                    top_k = st.slider("è¡¨ç¤ºä»¶æ•°ï¼ˆæ·»ä»˜æ›¸é¡TOPï¼‰", 10, 50, 20, step=5)
                    att_counts = att_series.value_counts().head(top_k)
                    att_df = att_counts.reset_index()
                    att_df.columns = ['æ·»ä»˜æ›¸é¡', 'ä»¶æ•°']
                    # é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆã‚°ãƒ©ãƒ•ä¸Šã§ä¸Šã‹ã‚‰ä¸‹ã¸å¤šã„é †ã«è¡¨ç¤ºï¼‰
                    att_df = att_df.sort_values('ä»¶æ•°', ascending=True)
                    fig_att = px.bar(
                        att_df,
                        x='ä»¶æ•°', y='æ·»ä»˜æ›¸é¡', orientation='h',
                        title=f"æ·»ä»˜æ›¸é¡ã®é »å‡ºï¼ˆTOP{top_k})",
                        labels={'ä»¶æ•°': 'ä»¶æ•°', 'æ·»ä»˜æ›¸é¡': 'æ·»ä»˜æ›¸é¡'}
                    )
                    fig_att.update_layout(margin=dict(l=0, r=0, t=40, b=0), height=520)
                    st.plotly_chart(fig_att, use_container_width=True)
                    with st.expander("ğŸ“¥ é›†è¨ˆCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                        st.download_button("æ·»ä»˜æ›¸é¡TOPã®CSV", df_to_csv_bytes(att_df), file_name="attachment_top.csv", mime="text/csv")
                else:
                    st.info("æ·»ä»˜æ›¸é¡ã®å€¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            st.divider()

            # --- ä¸‹æ®µï¼šã‚¯ãƒ­ã‚¹é›†è¨ˆï¼ˆæ·»ä»˜æ›¸é¡ Ã— æ‰‹ç¶šé¡å‹ï¼‰ ---
            if att_col in filtered_df.columns and 'æ‰‹ç¶šé¡å‹' in filtered_df.columns:
                st.subheader("ğŸ“Š æ·»ä»˜æ›¸é¡ Ã— æ‰‹ç¶šé¡å‹")
                att_series_for_ct = filtered_df[att_col].dropna().apply(_split_multi_values).explode().astype(str)
                att_series_for_ct = att_series_for_ct[att_series_for_ct.str.strip() != '']
                att_top = att_series_for_ct.value_counts().head(15).index if len(att_series_for_ct) > 0 else []
                if len(att_top) > 0:
                    exploded = filtered_df[[att_col, 'æ‰‹ç¶šé¡å‹']].dropna().copy()
                    exploded[att_col] = exploded[att_col].apply(_split_multi_values)
                    exploded = exploded.explode(att_col)
                    exploded = exploded[exploded[att_col].isin(att_top)]
                    ct = pd.crosstab(exploded[att_col], exploded['æ‰‹ç¶šé¡å‹'])
                    if ct.sum().sum() > 0:
                        ct = ct.loc[(ct.sum(axis=1)).sort_values(ascending=False).index]
                        fig_ct = px.imshow(ct, text_auto=True, aspect='auto', title='æ·»ä»˜æ›¸é¡ Ã— æ‰‹ç¶šé¡å‹ï¼ˆä»¶æ•°ï¼‰')
                        st.plotly_chart(fig_ct, use_container_width=True)
                        with st.expander("ğŸ“¥ ã‚¯ãƒ­ã‚¹é›†è¨ˆCSV"):
                            st.download_button("ã‚¯ãƒ­ã‚¹é›†è¨ˆCSV", df_to_csv_bytes(ct.reset_index()), file_name="attachment_by_type.csv", mime="text/csv")
                else:
                    st.info("æ·»ä»˜æ›¸é¡ã®ãƒˆãƒƒãƒ—ãŒå¾—ã‚‰ã‚Œãªã‹ã£ãŸãŸã‚ã€ã‚¯ãƒ­ã‚¹é›†è¨ˆã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“")
    
    with tab6:
        st.header("âš–ï¸ æ³•ä»¤ãƒ»æ‰‹ç¶šæ¤œç´¢")
        st.caption("æ³•ä»¤åã€æ³•ä»¤ç•ªå·ã€æ ¹æ‹ æ¡é …ã€æ‰‹ç¶šåã€æ‰‹ç¶šIDãªã©ã§æ¤œç´¢ã§ãã¾ã™")

        # --- æ³•ä»¤æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ  ---
        st.subheader("ğŸ“š æ³•ä»¤ã«ã‚ˆã‚‹æ¤œç´¢")
        col1, col2, col3 = st.columns(3)
        with col1:
            search_law_name = st.text_input(
                "æ³•ä»¤å",
                placeholder="ä¾‹ï¼šè¡Œæ”¿æ‰‹ç¶šæ³•",
                help=FIELD_DEFS.get('æ³•ä»¤å', '')
            )
        with col2:
            search_law_number = st.text_input(
                "æ³•ä»¤ç•ªå·",
                placeholder="ä¾‹ï¼šå¹³æˆ5å¹´æ³•å¾‹ç¬¬88å·",
                help=FIELD_DEFS.get('æ³•ä»¤ç•ªå·', '')
            )
        with col3:
            search_clause = st.text_input(
                "æ ¹æ‹ æ¡é …å·",
                placeholder="ä¾‹ï¼šç¬¬3æ¡",
                help=FIELD_DEFS.get('æ ¹æ‹ æ¡é …å·', '')
            )
        
        # --- æ‰‹ç¶šæ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ  ---
        st.subheader("ğŸ” æ‰‹ç¶šã«ã‚ˆã‚‹æ¤œç´¢")
        col1, col2 = st.columns(2)
        with col1:
            search_keyword = st.text_input(
                "æ‰‹ç¶šåã§æ¤œç´¢",
                placeholder="ä¾‹ï¼šè¨±å¯ç”³è«‹",
                help=FIELD_DEFS.get('æ‰‹ç¶šå', '')
            )
        with col2:
            search_id = st.text_input(
                "æ‰‹ç¶šIDã§æ¤œç´¢",
                placeholder="ä¾‹ï¼š12345",
                help="æ‰‹ç¶šã®å›ºæœ‰ID"
            )

        # ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢
        col1, col2 = st.columns(2)
        with col1:
            life_events_personal = st.multiselect(
                "ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆå€‹äººï¼‰",
                ["å‡ºç”Ÿ", "çµå©š", "å¼•è¶Šã—", "å°±è·ãƒ»è»¢è·", "ä»‹è­·", "æ­»äº¡ãƒ»ç›¸ç¶š", "ãã®ä»–"],
                help=FIELD_DEFS.get('æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)', '')
            )
        with col2:
            life_events_corporate = st.multiselect(
                "ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆæ³•äººï¼‰",
                ["æ³•äººã®è¨­ç«‹", "è·å“¡ã®æ¡ç”¨ãƒ»é€€è·", "äº‹å‹™æ‰€ã®æ–°è¨­ãƒ»ç§»è»¢", "æ³•äººã®åˆä½µãƒ»åˆ†å‰²", "ãã®ä»–"],
                help=FIELD_DEFS.get('æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)', '')
            )

        # å£«æ¥­æ¤œç´¢
        professions = st.multiselect(
            "é–¢é€£ã™ã‚‹å£«æ¥­",
            ["å¼è­·å£«", "å¸æ³•æ›¸å£«", "è¡Œæ”¿æ›¸å£«", "ç¨ç†å£«", "ç¤¾ä¼šä¿é™ºåŠ´å‹™å£«", "å…¬èªä¼šè¨ˆå£«", "å¼ç†å£«"],
            help=FIELD_DEFS.get('ç”³è«‹ã«é–¢é€£ã™ã‚‹å£«æ¥­', '')
        )

        # --- æ¤œç´¢å®Ÿè¡Œ ---
        search_df = filtered_df.copy()

        # æ³•ä»¤ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿
        if search_law_name:
            search_df = search_df[search_df['æ³•ä»¤å'].str.contains(search_law_name, na=False)]
        
        if search_law_number:
            search_df = search_df[search_df['æ³•ä»¤ç•ªå·'].str.contains(search_law_number, na=False)]
        
        if search_clause:
            search_df = search_df[search_df['æ ¹æ‹ æ¡é …å·'].str.contains(search_clause, na=False)]

        # æ‰‹ç¶šã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿
        if search_keyword:
            search_df = search_df[search_df['æ‰‹ç¶šå'].str.contains(search_keyword, na=False)]

        if search_id:
            search_df = search_df[search_df['æ‰‹ç¶šID'] == search_id]

        if life_events_personal:
            mask = search_df['æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)'].apply(
                lambda x: any(event in str(x) for event in life_events_personal)
            )
            search_df = search_df[mask]

        if life_events_corporate:
            mask = search_df['æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)'].apply(
                lambda x: any(event in str(x) for event in life_events_corporate)
            )
            search_df = search_df[mask]

        if professions:
            mask = search_df['ç”³è«‹ã«é–¢é€£ã™ã‚‹å£«æ¥­'].apply(
                lambda x: any(prof in str(x) for prof in professions)
            )
            search_df = search_df[mask]

        # --- çµæœè¡¨ç¤ºï¼†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---
        st.subheader(f"æ¤œç´¢çµæœ: {len(search_df)}ä»¶")

        if len(search_df) > 0:
            # è¡¨ç¤ºã‚«ãƒ©ãƒ ã®é¸æŠï¼ˆæ³•ä»¤æƒ…å ±ã‚’é‡è¦–ï¼‰
            available_columns = list(search_df.columns)
            default_columns = ["æ‰‹ç¶šID", "æ‰‹ç¶šå", "æ³•ä»¤å", "æ³•ä»¤ç•ªå·", "æ ¹æ‹ æ¡é …å·", "æ‰€ç®¡åºœçœåº", "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³"]
            # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ã‚’å«ã‚ã‚‹
            default_columns = [col for col in default_columns if col in available_columns]

            display_columns = st.multiselect(
                "è¡¨ç¤ºã™ã‚‹é …ç›®ã‚’é¸æŠ",
                available_columns,
                default=default_columns
            )

            if display_columns:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤ºç”¨ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
                display_df = search_df[display_columns].head(100).copy()
                
                # Streamlitã®Column Configurationã‚’ä½¿ç”¨ã—ã¦ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ã«ã™ã‚‹
                if 'æ‰‹ç¶šID' in display_columns:
                    # æ‰‹ç¶šIDãŒã‚ã‚‹å ´åˆã¯ã€é¸æŠæ©Ÿèƒ½ã‚’è¿½åŠ 
                    st.write("**ğŸ“‹ æ¤œç´¢çµæœ** â€»è¡Œã‚’é¸æŠã—ã¦è©³ç´°ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
                    event = st.dataframe(
                        display_df,
                        use_container_width=True,
                        height=400,
                        on_select="rerun",
                        selection_mode="single-row",
                        key="search_result_table"
                    )
                    
                    # é¸æŠã•ã‚ŒãŸè¡ŒãŒã‚ã‚‹å ´åˆ
                    if event.selection and event.selection.rows:
                        selected_row_idx = event.selection.rows[0]
                        selected_procedure = display_df.iloc[selected_row_idx]
                        
                        @st.dialog(f"ğŸ“„ æ‰‹ç¶šè©³ç´°: {selected_procedure.get('æ‰‹ç¶šå', '')[:30]}...", width="large")
                        def show_search_modal():
                            _render_procedure_detail(selected_procedure['æ‰‹ç¶šID'], df)
                        
                        col1, col2, col3 = st.columns([2, 1, 4])
                        with col1:
                            st.info(f"é¸æŠ: {selected_procedure['æ‰‹ç¶šID']}")
                        with col2:
                            if st.button("è©³ç´°ã‚’è¡¨ç¤º", type="primary"):
                                show_search_modal()
                        with col3:
                            # æ‰‹ç¶šåã‚’è¡¨ç¤º
                            st.text(f"{selected_procedure.get('æ‰‹ç¶šå', '')[:40]}...")
                else:
                    # æ‰‹ç¶šIDãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                    st.dataframe(
                        display_df,
                        use_container_width=True,
                        height=400
                    )

                # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ï¼‰
                st.download_button(
                    label="ğŸ“¥ æ¤œç´¢çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=df_to_csv_bytes(search_df[display_columns]),
                    file_name="search_results.csv",
                    mime="text/csv"
                )
    
    
    with tab7:
        st.header("ğŸ¤– é«˜åº¦ãªåˆ†æ(Î²)")
        st.info("ãƒ™ãƒ¼ã‚¿ç‰ˆï¼šæ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸé«˜åº¦ãªåˆ†ææ©Ÿèƒ½ã‚’æä¾›ã—ã¦ã„ã¾ã™")
        
        # ã‚µãƒ–ã‚¿ãƒ–ã‚’ä½œæˆ
        analysis_tab1, analysis_tab2, analysis_tab3 = st.tabs([
            "ğŸ”¬ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ»å„ªå…ˆåº¦åˆ†æ",
            "ğŸ“Š ç›¸é–¢åˆ†æ",
            "ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ"
        ])
        
        with analysis_tab1:
            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ
            st.subheader("ğŸ”¬ åºœçœåºã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ")
            
            # åºœçœåºã”ã¨ã®ç‰¹å¾´é‡ã‚’è¨ˆç®—
            ministry_features = filtered_df.groupby('æ‰€ç®¡åºœçœåº').agg({
                'æ‰‹ç¶šID': 'count',
                'ç·æ‰‹ç¶šä»¶æ•°': 'sum',
                'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°': 'sum',
                'éã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°': 'sum'
            }).reset_index()
        
            ministry_features.columns = ['åºœçœåº', 'æ‰‹ç¶šæ•°', 'ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°', 'éã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°']
            ministry_features['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡'] = (
                ministry_features['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°'] / ministry_features['ç·æ‰‹ç¶šä»¶æ•°'] * 100
            ).fillna(0)
            ministry_features['å¹³å‡æ‰‹ç¶šä»¶æ•°'] = ministry_features['ç·æ‰‹ç¶šä»¶æ•°'] / ministry_features['æ‰‹ç¶šæ•°']
            
            # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹åºœçœåºã®ã¿å¯¾è±¡
            ministry_features = ministry_features[ministry_features['ç·æ‰‹ç¶šä»¶æ•°'] > 100]
            
            if len(ministry_features) > 3:
                # ç‰¹å¾´é‡ã®æ¨™æº–åŒ–
                features_for_clustering = ['æ‰‹ç¶šæ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡', 'å¹³å‡æ‰‹ç¶šä»¶æ•°']
                X = ministry_features[features_for_clustering]
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                
                # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
                n_clusters = min(4, len(ministry_features) - 1)
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                ministry_features['ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'] = kmeans.fit_predict(X_scaled)
                
                # PCAã§2æ¬¡å…ƒã«å‰Šæ¸›ã—ã¦å¯è¦–åŒ–
                pca = PCA(n_components=2)
                X_pca = pca.fit_transform(X_scaled)
                ministry_features['PC1'] = X_pca[:, 0]
                ministry_features['PC2'] = X_pca[:, 1]
                
                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®å¯è¦–åŒ–
                fig_cluster = px.scatter(
                    ministry_features,
                    x='PC1',
                    y='PC2',
                    color='ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼',
                    hover_data=['åºœçœåº', 'æ‰‹ç¶šæ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡', 'å¹³å‡æ‰‹ç¶šä»¶æ•°'],
                    title=f"åºœçœåºã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœï¼ˆ{n_clusters}ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼‰",
                    labels={'PC1': f'ç¬¬1ä¸»æˆåˆ† ({pca.explained_variance_ratio_[0]:.1%})',
                            'PC2': f'ç¬¬2ä¸»æˆåˆ† ({pca.explained_variance_ratio_[1]:.1%})',
                            'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼': 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'}
                )
                st.plotly_chart(fig_cluster, use_container_width=True)
                
                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥ã®ç‰¹å¾´
                st.subheader("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥ç‰¹å¾´")
                cluster_stats = ministry_features.groupby('ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼')[features_for_clustering].mean().round(2)
                st.dataframe(cluster_stats, use_container_width=True)
                
                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥åºœçœåºãƒªã‚¹ãƒˆ
                st.subheader("ğŸ“‹ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥åºœçœåº")
                for cluster_id in sorted(ministry_features['ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'].unique()):
                    cluster_ministries = ministry_features[ministry_features['ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼'] == cluster_id]['åºœçœåº'].tolist()
                    st.write(f"**ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {cluster_id}:** {', '.join(cluster_ministries[:10])}{'...' if len(cluster_ministries) > 10 else ''}")
        
        # æ™‚ç³»åˆ—åˆ†æï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸï¼‰
        st.subheader("ğŸ“… ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸã®åˆ†æ")
        
        # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸã®åˆ†å¸ƒ
        time_data = filtered_df[filtered_df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸ'].notna()]['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸ'].value_counts()
        if len(time_data) > 0:
            fig_timeline = px.bar(
                x=time_data.index[:20],
                y=time_data.values[:20],
                title="ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å®Ÿæ–½æ™‚æœŸã®åˆ†å¸ƒï¼ˆTOP20ï¼‰",
                labels={'x': 'å®Ÿæ–½æ™‚æœŸ', 'y': 'æ‰‹ç¶šæ•°'}
            )
            fig_timeline.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_timeline, use_container_width=True)
            
            # äºˆæ¸¬åˆ†æ
            st.subheader("ğŸ”® ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–æ¨é€²ã®å„ªå…ˆåº¦åˆ†æ")
            
            # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã•ã‚Œã¦ã„ãªã„æ‰‹ç¶šã§ã€æ‰‹ç¶šä»¶æ•°ãŒå¤šã„ã‚‚ã®ã‚’æŠ½å‡º
            not_online = filtered_df[
                (filtered_df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³'].str.contains('æœªå®Ÿæ–½|æ¤œè¨ä¸­|äºˆå®šãªã—', na=False)) &
                (filtered_df['ç·æ‰‹ç¶šä»¶æ•°'] > 0)
            ].copy()
            
            if len(not_online) > 0:
                # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆæ‰‹ç¶šä»¶æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
                not_online['å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢'] = not_online['ç·æ‰‹ç¶šä»¶æ•°']
                
                # åºœçœåºã”ã¨ã«å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ
                priority_by_ministry = not_online.groupby('æ‰€ç®¡åºœçœåº')['å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢'].sum().sort_values(ascending=False).head(15)
                
                fig_priority = px.bar(
                    x=priority_by_ministry.values,
                    y=priority_by_ministry.index,
                    orientation='h',
                    title="ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å„ªå…ˆåº¦ãŒé«˜ã„åºœçœåºï¼ˆæœªå®Ÿæ–½æ‰‹ç¶šã®ç·ä»¶æ•°ãƒ™ãƒ¼ã‚¹ï¼‰",
                    labels={'x': 'å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ï¼ˆç·æ‰‹ç¶šä»¶æ•°ï¼‰', 'y': 'åºœçœåº'}
                )
                st.plotly_chart(fig_priority, use_container_width=True)
                
                # å„ªå…ˆåº¦ã®é«˜ã„å€‹åˆ¥æ‰‹ç¶š
                st.subheader("ğŸ¯ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–å„ªå…ˆåº¦TOP20æ‰‹ç¶š")
                top_priority = not_online.nlargest(20, 'å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢')[[
                    'æ‰‹ç¶šå', 'æ‰€ç®¡åºœçœåº', 'ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³'
                ]]
                st.dataframe(top_priority, use_container_width=True)
        
        with analysis_tab2:
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢åˆ†æ
            st.subheader("ğŸ”— æ‰‹ç¶šä»¶æ•°ã®ç›¸é–¢é–¢ä¿‚")
            
            numeric_cols = ['ç·æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°', 'éã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ‰‹ç¶šä»¶æ•°', 'ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ç‡']
            correlation_data = filtered_df[numeric_cols].corr()
        
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä½œæˆ
            fig_heatmap = go.Figure(data=go.Heatmap(
            z=correlation_data.values,
            x=correlation_data.columns,
            y=correlation_data.columns,
            colorscale='RdBu',
            zmid=0,
            text=correlation_data.values.round(2),
            texttemplate='%{text}',
            textfont={"size": 10},
            colorbar=dict(title="ç›¸é–¢ä¿‚æ•°")
            ))
            fig_heatmap.update_layout(
                title="æ‰‹ç¶šä»¶æ•°é–¢é€£æŒ‡æ¨™ã®ç›¸é–¢è¡Œåˆ—",
                width=600,
                height=500
            )
            st.plotly_chart(fig_heatmap, use_container_width=True)
            
            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®é–¢é€£æ€§åˆ†æ
            st.subheader("ğŸ“Š ã‚«ãƒ†ã‚´ãƒªé–“ã®é–¢é€£æ€§")
        
            # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³ã¨æ‰‹ç¶šé¡å‹ã®ã‚¯ãƒ­ã‚¹é›†è¨ˆ
            cross_tab = pd.crosstab(
            filtered_df['æ‰‹ç¶šé¡å‹'],
            filtered_df['ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã®å®Ÿæ–½çŠ¶æ³'],
            normalize='index'
            ) * 100
            
            # ä¸Šä½10ã®æ‰‹ç¶šé¡å‹ã®ã¿è¡¨ç¤º
            top_types = filtered_df['æ‰‹ç¶šé¡å‹'].value_counts().head(10).index
            cross_tab_top = cross_tab.loc[cross_tab.index.isin(top_types)]
            
            # ã‚¹ã‚¿ãƒƒã‚¯ãƒ‰ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
            fig_stacked = go.Figure()
            for col in cross_tab_top.columns:
                fig_stacked.add_trace(go.Bar(
                    name=col,
                    y=cross_tab_top.index,
                    x=cross_tab_top[col],
                    orientation='h'
                ))
            
            fig_stacked.update_layout(
                title="æ‰‹ç¶šé¡å‹åˆ¥ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–çŠ¶æ³ï¼ˆï¼…ï¼‰",
                barmode='stack',
                xaxis_title="å‰²åˆï¼ˆï¼…ï¼‰",
                yaxis_title="æ‰‹ç¶šé¡å‹",
                height=500
            )
            st.plotly_chart(fig_stacked, use_container_width=True)
            
            # åºœçœåºé–“ã®é¡ä¼¼åº¦åˆ†æ
            st.subheader("ğŸ¢ åºœçœåºé–“ã®é¡ä¼¼åº¦åˆ†æ")
        
            # åºœçœåºã”ã¨ã®æ‰‹ç¶šé¡å‹ã®åˆ†å¸ƒã‚’è¨ˆç®—
            ministry_procedure_matrix = pd.crosstab(
            filtered_df['æ‰€ç®¡åºœçœåº'],
            filtered_df['æ‰‹ç¶šé¡å‹']
            )
            
            # ä¸»è¦ãªåºœçœåºã®ã¿é¸æŠï¼ˆæ‰‹ç¶šæ•°ãŒå¤šã„ä¸Šä½20ï¼‰
            top_ministries = filtered_df['æ‰€ç®¡åºœçœåº'].value_counts().head(20).index
            ministry_procedure_matrix = ministry_procedure_matrix.loc[
                ministry_procedure_matrix.index.isin(top_ministries)
            ]
            
            if len(ministry_procedure_matrix) > 2:
                # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
                from sklearn.metrics.pairwise import cosine_similarity
                similarity_matrix = cosine_similarity(ministry_procedure_matrix)
                similarity_df = pd.DataFrame(
                    similarity_matrix,
                    index=ministry_procedure_matrix.index,
                    columns=ministry_procedure_matrix.index
                )
                
                # é¡ä¼¼åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
                fig_similarity = go.Figure(data=go.Heatmap(
                z=similarity_df.values,
                x=similarity_df.columns,
                y=similarity_df.index,
                colorscale='Viridis',
                text=similarity_df.values.round(2),
                texttemplate='%{text}',
                textfont={"size": 8},
                colorbar=dict(title="é¡ä¼¼åº¦")
                ))
                fig_similarity.update_layout(
                    title="åºœçœåºé–“ã®æ‰‹ç¶šé¡å‹é¡ä¼¼åº¦",
                    width=800,
                    height=700
                )
                fig_similarity.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig_similarity, use_container_width=True)
                
                # æœ€ã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹åºœçœåºãƒšã‚¢
                st.subheader("ğŸ¤ æœ€ã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹åºœçœåºãƒšã‚¢TOP10")
                similarity_pairs = []
                for i in range(len(similarity_df)):
                    for j in range(i+1, len(similarity_df)):
                        similarity_pairs.append({
                            'åºœçœåº1': similarity_df.index[i],
                            'åºœçœåº2': similarity_df.index[j],
                            'é¡ä¼¼åº¦': similarity_df.iloc[i, j]
                        })
                
                similarity_pairs_df = pd.DataFrame(similarity_pairs)
                top_similar = similarity_pairs_df.nlargest(10, 'é¡ä¼¼åº¦')
                st.dataframe(top_similar, use_container_width=True)
        
        with analysis_tab3:
            st.subheader("ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ")

        # å…±é€šã®æç”»ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        col_opt1, col_opt2, col_opt3 = st.columns(3)
        with col_opt1:
            top_n = st.slider("å¯¾è±¡ãƒãƒ¼ãƒ‰ã®ä¸Šé™ (TOP N)", 10, 100, 30, step=5, help="é »åº¦ã®é«˜ã„ãƒãƒ¼ãƒ‰ã‹ã‚‰ä¸Šä½Nä»¶ã«çµã‚Šã¾ã™")
        with col_opt2:
            min_w = st.slider("ã‚¨ãƒƒã‚¸ã®æœ€å°é‡ã¿ (ã—ãã„å€¤)", 1, 10, 2, step=1, help="å…±èµ·å›æ•°ã‚„é€£æºå›æ•°ãŒã“ã®å€¤æœªæº€ã®ã‚¨ãƒƒã‚¸ã¯éè¡¨ç¤º")
        with col_opt3:
            size_metric = st.selectbox("ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºæŒ‡æ¨™", ["degree", "betweenness", "eigenvector", "pagerank"], index=0)

        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®ç¨®é¡ã‚’é¸æŠ
        network_type = st.radio(
            "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®ç¨®é¡ã‚’é¸æŠ",
            ["åºœçœåºé–“ã®é€£æºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "æ‰‹ç¶šé¡å‹ã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"]
        )

        if network_type == "åºœçœåºé–“ã®é€£æºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯":
            st.subheader("ğŸ¢ åºœçœåºé–“ã®é€£æºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")

            required_cols = ['æ‰€ç®¡åºœçœåº', 'åºœçœå…±é€šæ‰‹ç¶š']
            if not _has_cols(filtered_df, required_cols):
                st.stop()

            with st.spinner("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ä¸­..."):
                common_procedures = filtered_df[_safe_notna(filtered_df['åºœçœå…±é€šæ‰‹ç¶š'])]
                if len(common_procedures) == 0:
                    st.warning("åºœçœå…±é€šæ‰‹ç¶šã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                else:
                    # ä¸Šä½Nåºœçœåºã«é™å®šã—ã¦ãƒã‚¤ã‚ºã‚’æŠ‘åˆ¶
                    ministries = filtered_df['æ‰€ç®¡åºœçœåº'].value_counts().head(top_n)

                    # åºœçœåºã”ã¨ã«ã€Œå…±é€šæ‰‹ç¶šã€ã®é›†åˆã‚’ä½œæˆ
                    group_sets = (
                        common_procedures.groupby('æ‰€ç®¡åºœçœåº')['åºœçœå…±é€šæ‰‹ç¶š']
                        .apply(lambda s: set([x for x in s.dropna().astype(str).tolist()]))
                        .to_dict()
                    )

                    G = nx.Graph()
                    for ministry in ministries.index:
                        G.add_node(ministry)

                    # å„ãƒšã‚¢ã®å…±é€šæ•°ã¨æ­£è¦åŒ–é‡ã¿ï¼ˆJaccardé¢¨ï¼‰ã‚’è¨ˆç®—
                    pairs = list(ministries.index)
                    for i in range(len(pairs)):
                        for j in range(i+1, len(pairs)):
                            a, b = pairs[i], pairs[j]
                            A, B = group_sets.get(a, set()), group_sets.get(b, set())
                            inter = len(A & B)
                            union = len(A | B)
                            if inter == 0 or union == 0:
                                continue
                            # é‡ã¿: å…±é€šä»¶æ•°ã¨æ­£è¦åŒ–ï¼ˆJaccardï¼‰ã‚’ä½µè¨˜
                            w_raw = inter
                            w_norm = inter / union
                            if w_raw >= min_w:
                                G.add_edge(a, b, weight=w_raw, norm_weight=round(w_norm, 3))

                    # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º = é¸æŠã—ãŸä¸­å¿ƒæ€§
                    cent = _compute_centrality(G, size_metric)
                    sizes = _scale_sizes(cent, min_size=8, max_size=40)
                    for n in G.nodes():
                        G.nodes[n]['size'] = sizes.get(n, 12)
                        G.nodes[n]['tooltip'] = f"{n}<br>{size_metric}: {cent.get(n, 0):.3f}"

                    if G.number_of_nodes() == 0 or G.number_of_edges() == 0:
                        st.warning("é€£æºã‚¨ãƒƒã‚¸ã‚’æ§‹æˆã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¾ãŸã¯ãƒ•ã‚£ãƒ«ã‚¿ãŒå³ã—ã™ãã¾ã™ï¼‰")
                    else:
                        enable_interactive = st.toggle("ãƒ‰ãƒ©ãƒƒã‚°å¯èƒ½ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤ºï¼ˆÎ²ï¼‰", value=True, key="net_ministry_interactive")
                        if enable_interactive:
                            _render_pyvis(G, height=700)
                        else:
                            pos = _layout_for_graph(G)

                            edge_trace = []
                            for (u, v, d) in G.edges(data=True):
                                x0, y0 = pos[u]
                                x1, y1 = pos[v]
                                w = d.get('weight', 1)
                                edge_trace.append(go.Scatter(
                                    x=[x0, x1, None], y=[y0, y1, None], mode='lines',
                                    line=dict(width=0.5 + w/5, color='#888'), hoverinfo='none'))

                            node_x, node_y, node_text, node_size = [], [], [], []
                            for node in G.nodes():
                                x, y = pos[node]
                                node_x.append(x); node_y.append(y)
                                node_text.append(G.nodes[node].get('tooltip', node))
                                node_size.append(G.nodes[node].get('size', 12))

                            node_trace = go.Scatter(
                                x=node_x, y=node_y, mode='markers+text', text=[str(n)[:10] for n in G.nodes()],
                                textposition="top center", hovertext=node_text, hoverinfo='text',
                                marker=dict(size=node_size, color='#1f77b4', line=dict(width=2, color='white'))
                            )

                            fig = go.Figure(data=edge_trace + [node_trace],
                                layout=go.Layout(title='åºœçœåºé–“ã®é€£æºãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', showlegend=False, hovermode='closest',
                                                 margin=dict(b=0,l=0,r=0,t=40),
                                                 xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                                 yaxis=dict(showgrid=False, zeroline=False, showticklabels=False), height=600))
                            st.plotly_chart(fig, use_container_width=True)
                        # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                        nodes_df, edges_df = _export_nodes_edges(G)
                        with st.expander("ğŸ“¥ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                            c1, c2 = st.columns(2)
                            with c1:
                                st.download_button("ãƒãƒ¼ãƒ‰CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_to_csv_bytes(nodes_df), file_name="network_nodes.csv", mime="text/csv")
                            with c2:
                                st.download_button("ã‚¨ãƒƒã‚¸CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_to_csv_bytes(edges_df), file_name="network_edges.csv", mime="text/csv")
                        st.info(f"ãƒãƒ¼ãƒ‰æ•°: {G.number_of_nodes()}, ã‚¨ãƒƒã‚¸æ•°: {G.number_of_edges()}")
                        st.caption("â€» ã‚¨ãƒƒã‚¸é‡ã¿=å…±é€šæ‰‹ç¶šã®ä»¶æ•°ï¼ˆè¡¨ç¤ºï¼‰ã€norm_weight=Jaccardé¢¨ã®æ­£è¦åŒ–ï¼ˆå†…éƒ¨å±æ€§ï¼‰")

        elif network_type == "æ‰‹ç¶šé¡å‹ã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯":
            st.subheader("ğŸ“ æ‰‹ç¶šé¡å‹ã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
            if not _has_cols(filtered_df, ['æ‰€ç®¡åºœçœåº', 'æ‰‹ç¶šé¡å‹']):
                st.stop()
            with st.spinner("å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ä¸­..."):
                # å‡ºç¾é »åº¦ã®é«˜ã„æ‰‹ç¶šé¡å‹ã«é™å®š
                procedure_types = filtered_df['æ‰‹ç¶šé¡å‹'].value_counts().head(top_n)
                target_types = set(procedure_types.index)

                # åºœçœåºã”ã¨ã®æ‰‹ç¶šé¡å‹é›†åˆ
                ministry_groups = filtered_df.groupby('æ‰€ç®¡åºœçœåº')['æ‰‹ç¶šé¡å‹'].apply(lambda s: set([x for x in s.dropna().tolist()]))

                # å„ã‚¿ã‚¤ãƒ—ã®å‡ºç¾æ•°
                type_freq = {t: 0 for t in target_types}
                for types in ministry_groups:
                    for t in types:
                        if t in type_freq:
                            type_freq[t] += 1

                # å…±èµ·å›æ•°ã¨æ­£è¦åŒ–é‡ã¿ï¼ˆcosineï¼‰
                from collections import defaultdict
                co_counts = defaultdict(int)
                for types in ministry_groups:
                    ts = [t for t in types if t in target_types]
                    for i in range(len(ts)):
                        for j in range(i+1, len(ts)):
                            a, b = sorted((ts[i], ts[j]))
                            co_counts[(a, b)] += 1

                G = nx.Graph()
                for t in target_types:
                    G.add_node(t)

                for (a, b), c in co_counts.items():
                    w = _cosine_normalized_weight(c, type_freq.get(a, 1), type_freq.get(b, 1))
                    if c >= min_w and w > 0:
                        G.add_edge(a, b, weight=c, norm_weight=round(w, 3))

                # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º = é¸æŠã—ãŸä¸­å¿ƒæ€§
                cent = _compute_centrality(G, size_metric)
                sizes = _scale_sizes(cent, min_size=8, max_size=40)
                for n in G.nodes():
                    G.nodes[n]['size'] = sizes.get(n, 12)
                    G.nodes[n]['tooltip'] = f"{n}<br>{size_metric}: {cent.get(n, 0):.3f}"

                if G.number_of_nodes() > 0:
                    enable_interactive = st.toggle("ãƒ‰ãƒ©ãƒƒã‚°å¯èƒ½ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤ºï¼ˆÎ²ï¼‰", value=True, key="net_cooccurrence_interactive")
                    if enable_interactive:
                        _render_pyvis(G, height=700)
                    else:
                        pos = _layout_for_graph(G)

                        # ã‚¨ãƒƒã‚¸ã®æç”»
                        edge_trace = []
                        for edge in G.edges(data=True):
                            x0, y0 = pos[edge[0]]
                            x1, y1 = pos[edge[1]]
                            weight = edge[2].get('weight', 1)
                            edge_trace.append(go.Scatter(
                                x=[x0, x1, None],
                                y=[y0, y1, None],
                                mode='lines',
                                line=dict(width=0.5 + weight/5, color='#888'),
                                hoverinfo='none'
                            ))

                        # ãƒãƒ¼ãƒ‰ã®æç”»
                        node_x, node_y, node_text, node_size = [], [], [], []
                        for node in G.nodes():
                            x, y = pos[node]
                            node_x.append(x)
                            node_y.append(y)
                            node_text.append(G.nodes[node].get('tooltip', node))
                            node_size.append(G.nodes[node].get('size', 12))

                        node_trace = go.Scatter(
                            x=node_x,
                            y=node_y,
                            mode='markers',
                            hovertext=node_text,
                            hoverinfo='text',
                            marker=dict(
                                size=node_size,
                                color='#ff7f0e',
                                line=dict(width=2, color='white')
                            )
                        )

                        fig = go.Figure(data=edge_trace + [node_trace],
                                       layout=go.Layout(
                                           title='æ‰‹ç¶šé¡å‹ã®å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯',
                                           showlegend=False,
                                           hovermode='closest',
                                           margin=dict(b=0,l=0,r=0,t=40),
                                           xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                           yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                           height=600
                                       ))

                        st.plotly_chart(fig, use_container_width=True)
                    # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                    nodes_df, edges_df = _export_nodes_edges(G)
                    with st.expander("ğŸ“¥ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                        c1, c2 = st.columns(2)
                        with c1:
                            st.download_button("ãƒãƒ¼ãƒ‰CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_to_csv_bytes(nodes_df), file_name="network_nodes.csv", mime="text/csv")
                        with c2:
                            st.download_button("ã‚¨ãƒƒã‚¸CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_to_csv_bytes(edges_df), file_name="network_edges.csv", mime="text/csv")
                    st.info(f"ãƒãƒ¼ãƒ‰æ•°: {G.number_of_nodes()}, ã‚¨ãƒƒã‚¸æ•°: {G.number_of_edges()}")
                    st.caption("â€» ã‚¨ãƒƒã‚¸é‡ã¿=å…±èµ·å›æ•°ã€norm_weight=cosineæ­£è¦åŒ–ï¼ˆå†…éƒ¨å±æ€§ï¼‰")

        else:  # ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
            st.subheader("ğŸŒŸ ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
            if not _has_cols(filtered_df, ['æ‰‹ç¶šé¡å‹', 'æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)', 'æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)']):
                st.stop()
            with st.spinner("ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ä¸­..."):
                G = nx.Graph()

                def _split_events(val: Any) -> List[str]:
                    if val is None or (isinstance(val, float) and np.isnan(val)):
                        return []
                    s = str(val).strip()
                    if s.lower() == 'nan' or s == '':
                        return []
                    for sep in ['ã€', ',', 'ï¼Œ', ';', 'ï¼›']:
                        s = s.replace(sep, 'ã€')
                    return [e.strip() for e in s.split('ã€') if e.strip()]

                from collections import Counter
                life_events_personal = []
                for events in filtered_df['æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)']:
                    life_events_personal.extend(_split_events(events))
                life_events_corporate = []
                for events in filtered_df['æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)']:
                    life_events_corporate.extend(_split_events(events))

                personal_counter = Counter(life_events_personal)
                corporate_counter = Counter(life_events_corporate)

                top_personal = dict(personal_counter.most_common(top_n//2))
                top_corporate = dict(corporate_counter.most_common(top_n//2))

                for event, count in top_personal.items():
                    G.add_node(f"å€‹äºº: {event}", size=int(np.log(count + 1) * 10), category="personal")
                for event, count in top_corporate.items():
                    G.add_node(f"æ³•äºº: {event}", size=int(np.log(count + 1) * 10), category="corporate")

                top_proc_types = set(filtered_df['æ‰‹ç¶šé¡å‹'].value_counts().head(15).index)
                sub = filtered_df[filtered_df['æ‰‹ç¶šé¡å‹'].isin(top_proc_types)]
                for _, row in sub.iterrows():
                    proc_type = row['æ‰‹ç¶šé¡å‹']
                    for event in _split_events(row['æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(å€‹äºº)']):
                        node_name = f"å€‹äºº: {event}"
                        if event in top_personal and node_name in G.nodes:
                            if proc_type not in G.nodes:
                                G.add_node(proc_type, size=5, category="procedure")
                            G.add_edge(node_name, proc_type)
                    for event in _split_events(row['æ‰‹ç¶šãŒè¡Œã‚ã‚Œã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ(æ³•äºº)']):
                        node_name = f"æ³•äºº: {event}"
                        if event in top_corporate and node_name in G.nodes:
                            if proc_type not in G.nodes:
                                G.add_node(proc_type, size=5, category="procedure")
                            G.add_edge(node_name, proc_type)

                # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º = é¸æŠã—ãŸä¸­å¿ƒæ€§ï¼ˆç¨®é¡ã«é–¢ä¿‚ãªãï¼‰
                cent = _compute_centrality(G, size_metric)
                sizes = _scale_sizes(cent, min_size=8, max_size=40)
                for n in G.nodes():
                    G.nodes[n]['size'] = sizes.get(n, 12)
                    tt = f"{n}<br>{size_metric}: {cent.get(n, 0):.3f}"
                    G.nodes[n]['tooltip'] = tt

                if G.number_of_nodes() == 0:
                    st.warning("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹æˆã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¾ãŸã¯ãƒ•ã‚£ãƒ«ã‚¿ãŒå³ã—ã™ãã¾ã™ï¼‰")
                else:
                    enable_interactive = st.toggle("ãƒ‰ãƒ©ãƒƒã‚°å¯èƒ½ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¡¨ç¤ºï¼ˆÎ²ï¼‰", value=True, key="net_lifeevent_interactive")
                    if enable_interactive:
                        _render_pyvis(G, height=700)
                    else:
                        pos = _layout_for_graph(G)

                        edge_trace = []
                        for (u, v) in G.edges():
                            x0, y0 = pos[u]
                            x1, y1 = pos[v]
                            edge_trace.append(go.Scatter(
                                x=[x0, x1, None], y=[y0, y1, None], mode='lines',
                                line=dict(width=0.5, color='#888'), hoverinfo='none'))

                        node_traces = []
                        categories = {'personal': '#2ca02c', 'corporate': '#d62728', 'procedure': '#9467bd'}
                        symbols = {'personal': 'circle', 'corporate': 'square', 'procedure': 'diamond'}

                        for cat, color in categories.items():
                            node_x, node_y, node_text, node_size = [], [], [], []
                            for node in G.nodes():
                                if G.nodes[node].get('category', 'procedure') == cat:
                                    x, y = pos[node]
                                    node_x.append(x); node_y.append(y)
                                    node_text.append(G.nodes[node].get('tooltip', node))
                                    node_size.append(G.nodes[node].get('size', 10))
                            if node_x:
                                node_traces.append(go.Scatter(
                                    x=node_x, y=node_y, mode='markers', name={'personal': 'å€‹äººã‚¤ãƒ™ãƒ³ãƒˆ', 'corporate': 'æ³•äººã‚¤ãƒ™ãƒ³ãƒˆ', 'procedure': 'æ‰‹ç¶šé¡å‹'}[cat],
                                    hovertext=node_text, hoverinfo='text',
                                    marker=dict(size=node_size, color=color, symbol=symbols[cat], line=dict(width=2, color='white'))
                                ))

                        fig = go.Figure(data=edge_trace + node_traces,
                            layout=go.Layout(title='ãƒ©ã‚¤ãƒ•ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', showlegend=True, hovermode='closest',
                                             margin=dict(b=0,l=0,r=0,t=40),
                                             xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                             yaxis=dict(showgrid=False, zeroline=False, showticklabels=False), height=600))
                        st.plotly_chart(fig, use_container_width=True)
                    # CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                    nodes_df, edges_df = _export_nodes_edges(G)
                    with st.expander("ğŸ“¥ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                        c1, c2 = st.columns(2)
                        with c1:
                            st.download_button("ãƒãƒ¼ãƒ‰CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_to_csv_bytes(nodes_df), file_name="network_nodes.csv", mime="text/csv")
                        with c2:
                            st.download_button("ã‚¨ãƒƒã‚¸CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df_to_csv_bytes(edges_df), file_name="network_edges.csv", mime="text/csv")
                    st.info(f"ãƒãƒ¼ãƒ‰æ•°: {G.number_of_nodes()}, ã‚¨ãƒƒã‚¸æ•°: {G.number_of_edges()}")
                    st.caption("â€» ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã¯ä¸­å¿ƒæ€§ã«åŸºã¥ãã¾ã™ï¼ˆé¸æŠå¯èƒ½ï¼‰")

if __name__ == "__main__":
    main()
